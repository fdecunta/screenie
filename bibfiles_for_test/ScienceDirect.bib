@article{GAN2025107976,
title = {A deep learning model based on data decomposition and modern convolution for predicting influent characteristics of wastewater treatment plant},
journal = {Journal of Water Process Engineering},
volume = {75},
pages = {107976},
year = {2025},
issn = {2214-7144},
doi = {https://doi.org/10.1016/j.jwpe.2025.107976},
url = {https://www.sciencedirect.com/science/article/pii/S2214714425010487},
author = {Lin Gan and Ao Li and Ji Li and Zhizhang Shen},
keywords = {Influent prediction, Wastewater treatment, Data decomposition, Attention mechanism, Model interpretability},
abstract = {Accurate prediction of influent flow and water quality indicators in wastewater treatment plants (WWTPs) is essential for optimizing operational efficiency, reducing energy consumption, and ensuring regulatory compliance. To enhance predictive accuracy, this study presents a novel hybrid deep learning model, STL-mTCNA, which integrates seasonal-trend decomposition using LOESS (STL), modern temporal convolutional networks (ModernTCN), and an attention mechanism. The model was trained and validated using real-world influent data collected over an extended period. Comparative experiments against baseline models, including XGBoost, LSTM, GRU, and ModernTCN, demonstrate that STL-mTCNA significantly outperforms existing approaches. Specifically, for total nitrogen (TN) and total phosphorus (TP) predictions, our model achieves reductions of over 40 % in root mean square error (RMSE) and improvements exceeding 30 % in the coefficient of determination (R2). Additionally, DeepLIFT-based interpretability analysis highlights the importance of historical influent patterns, with extended dependencies observed for TN and ammonia nitrogen (NH3-N). Ablation studies confirm the essential roles of STL decomposition and auxiliary variables in enhancing model performance. These findings underscore the potential of advanced hybrid deep learning models in improving WWTP management through precise influent forecasting. Future research will explore strategies to mitigate potential information leakage in data decomposition and incorporate external environmental factors to further refine predictive capabilities.}
}
@article{HUNTER2023102076,
title = {Using hierarchical text classification to investigate the utility of machine learning in automating online analyses of wildlife exploitation},
journal = {Ecological Informatics},
volume = {75},
pages = {102076},
year = {2023},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2023.102076},
url = {https://www.sciencedirect.com/science/article/pii/S157495412300105X},
author = {Sara Bronwen Hunter and Fiona Mathews and Julie Weeds},
keywords = {Machine learning, Natural language processing, iEcology, Wildlife exploitation, Digital conservation, Social media},
abstract = {Expanding digital data sources, including social media, online news articles and blogs, provide an opportunity to understand better the context and intensity of human-nature interactions, such as wildlife exploitation. However, online searches encompassing large taxonomic groups can generate vast datasets, which can be overwhelming to filter for relevant content without the use of automated tools. The variety of machine learning models available to researchers, and the need for manually labelled training data with an even balance of labels, can make applying these tools challenging. Here, we implement and evaluate a hierarchical text classification pipeline which brings together three binary classification tasks with increasingly specific relevancy criteria. Crucially, the hierarchical approach facilitates the filtering and structuring of a large dataset, of which relevant sources make up a small proportion. Using this pipeline, we also investigate how the accuracy with which text classifiers identify relevant and irrelevant texts is influenced by the use of different models, training datasets, and the classification task. To evaluate our methods, we collected data from Facebook, Twitter, Google and Bing search engines, with the aim of identifying sources documenting the hunting and persecution of bats (Chiroptera). Overall, the ‘state-of-the-art’ transformer-based models were able to identify relevant texts with an average accuracy of 90%, with some classifiers achieving accuracy of >95%. Whilst this demonstrates that application of more advanced models can lead to improved accuracy, comparable performance was achieved by simpler models when applied to longer documents and less ambiguous classification tasks. Hence, the benefits from using more computationally expensive models are dependent on the classification context. We also found that stratification of training data, according to the presence of key search terms, improved classification accuracy for less frequent topics within datasets, and therefore improves the applicability of classifiers to future data collection. Overall, whilst our findings reinforce the usefulness of automated tools for facilitating online analyses in conservation and ecology, they also highlight that the effectiveness and appropriateness of such tools is determined by the nature and volume of data collected, the complexity of the classification task, and the computational resources available to researchers.}
}
@article{TEJADASANCHEZ2025102654,
title = {English medium instruction practices in the internationalized university: The cases of Colombia and South Korea},
journal = {International Journal of Educational Research},
volume = {133},
pages = {102654},
year = {2025},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2025.102654},
url = {https://www.sciencedirect.com/science/article/pii/S0883035525001284},
author = {Isabel Tejada-Sánchez and Mario Molina-Naar},
keywords = {English Medium Instruction, Practices, Internationalization, ROAD MAPPING, higher education},
abstract = {This study examines English Medium Instruction (EMI) in higher education institutions in Colombia and South Korea. Using qualitative content analysis, data from professor interviews, classroom observations, and educational artifacts were analyzed through Kemmis' practice architecture and the ROAD-MAPPING frameworks. Findings reveal three practice configurations: Sayings (EMI within prospective academic communities), Doings (EMI embodying expanded disciplinary perspectives), and Relatings (EMI fostering rapport and adaptability). These categories illustrate EMI patterns across contexts, highlighting unique ecologies from institutional structures, pedagogy, and social relationships. The study underscores the importance of contextual approaches for effective EMI application and supports flexible language policies balancing English's global role with linguistic diversity. By integrating sayings, doings, and relatings with the ROAD-MAPPING framework, the analysis provides deeper insights into EMI practices in international higher education.}
}
@article{DENICOLA20251943,
title = {A NLP Approach to Quantify Resilience in Cyber-Socio-Technical Systems with LLM Agents},
journal = {Procedia Computer Science},
volume = {253},
pages = {1943-1950},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.256},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925002649},
author = {Antonio {De Nicola} and Maria Guariglia Migliore and Ida Mele and Maria Luisa Villani},
keywords = {Cyber-Socio-Technical System, Large Language Model, Natural Language Processing, Resilience, Safety},
abstract = {Incorporating cyber artifacts into Cyber-Socio-Technical Systems (CSTSs) poses new challenges to human safety due to their increasingly unpredictable behavior. Resilience is the ability to adapt, recover, and bounce back from challenges, setbacks, or adversity. Quantifying the resilience of CSTSs requires the identification of leading or lagging indicators. Among the leading indicators, allostatic load measures the level of systemic tension accumulated from misalignments in the perspectives of system actors regarding how work should be performed. In this paper, we propose a novel approach based on Natural Language Processing (NLP) to measure allostatic load. This approach involves lightweight modelling of process perspectives, extraction of token vectors from process function descriptions, and computing vector similarity by using the Dice similarity algorithm. Then, allostatic load is defined as the complement to one of the similarity value. An example application concerning a chemical spill in a hospital laboratory demonstrates the method’s practical use.}
}
@article{NICHOLSONTHOMAS2024102819,
title = {Harnessing artificial intelligence for efficient systematic reviews: A case study in ecosystem condition indicators},
journal = {Ecological Informatics},
volume = {83},
pages = {102819},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102819},
url = {https://www.sciencedirect.com/science/article/pii/S1574954124003613},
author = {Isabel {Nicholson Thomas} and Philip Roche and Adrienne Grêt-Regamey},
keywords = {Artificial intelligence, Systematic review, Ecosystem condition, GPT},
abstract = {Effective evidence synthesis is important for the integration of scientific research into decision-making. However, fully depicting the vast mosaic of concepts and applications in environmental sciences and ecology often entails a substantial workload. New Artificial Intelligence (AI) tools present an attractive option for addressing this challenge but require sufficient validation to match the vigorous standards of a systematic review. This article demonstrates the use of generative AI in the selection of relevant literature as part of a systematic review on indicators of ecosystem condition. We highlight, through the development of an optimal prompt to communicate inclusion and exclusion criteria, the need to describe ecosystem condition as a multidimensional concept whilst also maintaining clarity on what does not meet the criteria of comprehensiveness. We show that, although not completely infallible, the GPT-3.5 model significantly outperforms traditional literature screening processes in terms of speed and efficiency whilst correctly selecting 83 % of relevant literature for review. Our study highlights the importance of precision in prompt design and the setting of query parameters for the AI model and opens the perspective for future work using language models to contextualize complex concepts in the environmental sciences. Future development of this methodology in tandem with the continued evolution of the accessibility and capacity of AI tools presents a great potential to improve evidence synthesis through gains in efficiency and possible scope.}
}
@article{PACCOU2025100341,
title = {Exploring the AI electricity crisis scenario: A case study of Texas-ERCOT},
journal = {Next Energy},
volume = {8},
pages = {100341},
year = {2025},
issn = {2949-821X},
doi = {https://doi.org/10.1016/j.nxener.2025.100341},
url = {https://www.sciencedirect.com/science/article/pii/S2949821X25001048},
author = {Rémi Paccou and Fons Wijnhoven},
keywords = {Artificial intelligence, Generative AI, Data centers, AI electricity consumption, Scenarios},
abstract = {This article explores artificial intelligence (AI) effects on data center electricity consumption by answering the question if and when AI growth may cause an electricity crisis. We study this through combining 3 AI demand electricity and 3 electricity supply scenarios to 9 scenarios and simulating these for estimating their longer-term outcomes on anticipated reserve margins (ARM). These scenarios contain multiple theoretical constructs for explaining AI impact on data centers via a system dynamics narrative, i.e. non-linear predictions with feedback mechanisms through time. We apply our system dynamics simulation model to a specific region because possible conflicts between data center electricity demand and electricity supply capacity manifest themselves only at a regional level. As a case for our simulations, we selected Texas-Electric Reliability Council of Texas (ERCOT): an electricity region covering most of the state of Texas. Being a very energy rich area, we see only a few conditions in which an AI electricity crisis, i.e., an ARM below the reference margin level (RML), may happen in Texas-ERCOT, but a decline of the ARM from 31.2% in 2025 to between 7 (which is below the needed 13.75% RML) and 25% in 2030 with data centers taking about 21–26% of all electricity available may likely happen around 2030. The application of our method in other regions may give very different outcomes, but also the Texas-ERCOT region is not free of risks. While this paper focuses on direct AI impacts, it also suggests the need for future studies exploring the indirect effects of increased data center usage on the economy, society, and ecology.}
}
@article{CORNELIUS2025,
title = {From literature to biodiversity data: mining arthropod organismal traits with machine learning},
journal = {Biodiversity Data Journal},
volume = {13},
year = {2025},
issn = {1314-2836},
doi = {https://doi.org/10.3897/BDJ.13.e153070},
url = {https://www.sciencedirect.com/science/article/pii/S1314283625001733},
author = {Joseph Cornelius and Harald Detering and Oscar Lithgow-Serrano and Donat Agosti and Fabio Rinaldi and Robert M Waterhouse},
keywords = {arthropods, biodiversity, natural language processing, text and data mining, trait database},
abstract = {The fields of taxonomy and biodiversity research have witnessed an exponential growth in published literature. This vast corpus of articles holds information on the diverse biological traits of organisms and their ecologies. However, access to and extraction of relevant data from this extensive resource remain challenging. Advances in text and data mining (TDM) and Natural Language Processing (NLP) techniques offer new opportunities for liberating such information from literature. Testing and using such approaches to annotate articles in machine-actionable formats is, therefore, necessary to enable the exploitation of existing knowledge in new biology, ecology and evolution research. Here, we explore the potential of these methods to annotate and extract organismal trait data for the most diverse animal group on Earth, the arthropods. The article processing workflow uses manually curated trait dictionaries with trained NLP models to perform labelling of entities and relationships of thousands of articles. A subset of manually annotated documents facilitated the formal evaluation of the performance of the workflow in terms of entity recognition and normalisation and relationship extraction, highlighting several important technical challenges. The results are made available to the scientific community through an interactive web tool and queryable resource, the ArTraDB Arthropod Trait Database. These methodological explorations provide a framework that could be extended beyond the arthropods, where TDM and NLP approaches applied to the taxonomy and biodiversity literature will greatly facilitate data synthesis studies and literature reviews, the identification of knowledge gaps and biases, as well as the data-informed investigation of ecological and evolutionary trends and patterns.}
}
@article{LONG2025136856,
title = {Study on the theme evolution and regional differences of new energy industrial policy based on natural language processing technology},
journal = {Energy},
volume = {331},
pages = {136856},
year = {2025},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2025.136856},
url = {https://www.sciencedirect.com/science/article/pii/S0360544225024983},
author = {Ruyin Long and Shilin Guo and Meifen Wu and Jingwen Na},
keywords = {New energy industry, Policy research, Python natural language processing, Topic evolution, Regional difference},
abstract = {In the context of accelerating the development of a new energy system, the rapid growth of the new energy industry has become a key driver in achieving China's dual-carbon goals and fostering economic and social transformation. Leveraging technological advancements and robust policy support, China has made significant strides in the development and utilization of wind, solar and hydrogen energy, culminating in the establishment of a comprehensive industrial chain. This study analyzes 2730 new energy Industrial policies issued by central and local governments, employing Natural Language Processing techniques for keyword extraction, thematic analysis, and semantic similarity assessment. The results indicate that, while central policies provide substantial support for the new energy sector, regional responses exhibit considerable variability. The evolution of China's new energy industrial policy can be categorized into three distinct stages, with regions tailoring their policies to local resource endowments and developmental priorities: the eastern region focusing on technological innovation and synergy, the central on infrastructure and markets, the western on resource exploitation and projects, and the northeast on technological upgrading. Additionally, notable discrepancies in policy content across provinces were observed. Based on these findings, the study offers targeted recommendations for optimizing China's new energy industrial policy framework.}
}
@article{ROBINSON2024100087,
title = {Infrastructural justice for responsible software engineering,},
journal = {Journal of Responsible Technology},
volume = {19},
pages = {100087},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100087},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000131},
author = {Sarah Robinson and Jim Buckley and Luigina Ciolfi and Conor Linehan and Clare McInerney and Bashar Nuseibeh and John Twomey and Irum Rauf and John McCarthy},
keywords = {Responsible software engineering, Infrastructure, Social connection model of responsibility, Installed base, Deepfake technology},
abstract = {In recent years, we have seen many examples of software products unintentionally causing demonstrable harm. Many guidelines for ethical and responsible computing have been developed in response. Dominant approaches typically attribute liability and blame to individual companies or actors, rather than understanding how the working practices, norms, and cultural understandings in the software industry contribute to such outcomes. In this paper, we propose an understanding of responsibility that is infrastructural, relational, and cultural; thus, providing a foundation to better enable responsible software engineering into the future. Our approach draws on Young's (2006) social connection model of responsibility and Star and Ruhleder's (1994) concept of infrastructure. By bringing these theories together we introduce a concept called infrastructural injustice, which offers a new way for software engineers to consider their opportunities for responsible action with respect to society and the planet. We illustrate the utility of this approach by applying it to an Open-Source software communities’ development of Deepfake technology, to find key leverage points of responsibility that are relevant to both Deepfake technology and software engineering more broadly.}
}
@article{STENHOUSE2025,
title = {SpeciMate: Improving metadata extraction from digitised biological specimens},
journal = {Biodiversity Data Journal},
volume = {13},
year = {2025},
issn = {1314-2836},
doi = {https://doi.org/10.3897/BDJ.13.e160553},
url = {https://www.sciencedirect.com/science/article/pii/S1314283625001691},
author = {Alan Stenhouse and Peter H. Thrall},
keywords = {specimen, digitisation, metadata, AI, software application, data curation},
abstract = {Background
The digitisation of natural history collections represents a critical step towards preserving and increasing accessibility to valuable scientific data. Despite their fundamental importance to taxonomy, ecology and conservation, the world’s natural history collections remain underutilised due to the labour-intensive process of extracting metadata from specimen labels.
New information
This paper describes SpeciMate, a software application that uses a human-AI collaborative approach to accelerate the extraction of metadata from digitised specimen images. The system leverages artificial intelligence web services including optical character recognition (OCR), automated translation and large language and multimodal models (LLMs) to extract structured metadata, while requiring human expertise for prompt engineering and data curation. We describe the application's architecture, functionality and workflows, which enable effective processing of various specimen types including herbarium sheets and insect slides. Our trials indicate that this tool significantly improves the efficiency of metadata extraction while maintaining high data quality. The combination of automated AI processing with human supervision and refinement represents a promising approach to accelerating the digitisation and databasing of natural history collections, thereby enabling broader access to these invaluable resources for research, education and conservation efforts.}
}
@article{KONG2024101432,
title = {A comparative genre analysis of AI-generated and scholar-written abstracts for English review articles in international journals},
journal = {Journal of English for Academic Purposes},
volume = {71},
pages = {101432},
year = {2024},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2024.101432},
url = {https://www.sciencedirect.com/science/article/pii/S1475158524001000},
author = {Xinwan Kong and Chengyu Liu},
keywords = {ChatGPT, Rhetorical moves, Review article abstracts, Genre analysis, Disciplinary variation},
abstract = {There has been growing interest in the performance and efficiency of ChatGPT in generating academic texts. However, little empirical research has been conducted on its performance in producing review article abstracts. This study adopts the genre analysis approach to investigate the rhetorical moves of review article abstracts in hard and soft science disciplines based on two self-compiled corpora, respectively including 160 scholar-written abstracts from four high-impact international journals, and 160 abstracts generated by ChatGPT, with an aim to reveal the similarities and differences between human-written and AI-generated English review article abstracts. The results show significant differences between human-written and ChatGPT-generated abstracts, first in the frequency of three out of the five moves, and then in the sequential order of moves, with each type of abstracts demonstrating a preference for move sequence patterns as well as obligatory and optional elements. The two types of abstracts differ significantly in the frequency of move embedding, but share the same embedding combination patterns. These findings may deepen our understanding of ChatGPT's capabilities and limitations in generating academic texts across different disciplines, help improve the generative AI system, then highlight the complex relationship among the structure of academic abstracts, discipline cultures and genre knowledge.}
}
@article{WEN2025141,
title = {“Phenology description is all you need!” mapping unknown crop types with remote sensing time-series and LLM generated text alignment},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {228},
pages = {141-165},
year = {2025},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2025.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0924271625002643},
author = {Siyuan Wen and Wenzhi Zhao and Fengcheng Ji and Rui Peng and Liqiang Zhang and Qiao Wang},
keywords = {Crop classification, Zero-shot learning, Time-series data, Vision-language model},
abstract = {Accurate crop monitoring is crucial for global food security and sustainable agricultural management. Previously published studies are almost all trained in closed environments, limiting their capability to generalize beyond the training areas or to unseen crop categories, thus severely constraining the scalability and adaptability of crop monitoring. Zero-shot learning (ZSL)-based classification methods have made significant progress recently and provide an effective solution to the above challenges, which establishes the connection between seen and unseen categories through semantic knowledge. However, the semantic knowledge extracted by these methods often lacks the domain-specific details to distinguish different crop types. To this end, we propose a novel contrastive learning framework to explore the application of zero-shot learning in crop classification for the first time. Specifically, our method extracts visual features from time-series patches and the corresponding curves, then utilizes a large language model (LLM) to automatically generate high-quality time-series text descriptions. These descriptions provide unique phenological information and growth patterns for each crop type. Additionally, we further process keywords related to phenological information and growth patterns through a graph convolutional network (GCN) to effectively capture the interrelated phenological stages and spatial dependencies. Experimental results on three different study areas demonstrate that our approach outperforms traditional supervised learning methods for crop classification as well as ZSL baseline methods. Our findings highlight the effectiveness and interpretability of leveraging time series data to explore visual information and semantic knowledge of crops for zero-shot crop classification across diverse regions and crop types. Code and pretrained model are available at https://github.com/Shawie66/Phenology-Description-Is-All-You-Need.}
}
@article{WANG2025145911,
title = {Rising attention and shifting themes in green supply chain discourse: Evidence from Weibo (2012–2024)},
journal = {Journal of Cleaner Production},
volume = {518},
pages = {145911},
year = {2025},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2025.145911},
url = {https://www.sciencedirect.com/science/article/pii/S0959652625012612},
author = {Shi Wang and Yaxin Hu and Zhan Zhao and Jiacong Cai and Jianxun Yang and Miaomiao Liu and Wen Fang and Zongwei Ma and Jun Bi},
keywords = {Green supply chain, Social media, Topic analysis, Opinion leaders, Industries},
abstract = {Social media have become a crucial platform for public engagement and policy discourse in China, playing an increasingly important role in green supply chain development. This study analyzes 0.24 million original Weibo posts from 2012 to 2024, the longest time series to date, to examine the evolution of green supply chain discourse. We built a data analysis framework to capture spatiotemporal trends, thematic shifts, user heterogeneity across industry contexts. Our findings show that public attention to green supply chains surged after 2020, coinciding with major national strategies such as the Dual Carbon goal and the Beautiful China initiative. We identified 42 real-world social events driving these hot discussions, ranging from early environmental incidents to key policy meetings and releases in later years. The discourse is concentrated in economically developed coastal regions and is mainly shaped by enterprises, government agencies, and media actors. Over time, the thematic focus shifted from environmental protection topics to supply chain management related items, including green production, logistics, and sales. This trend reflects growing interest in practical, system-level approaches to green implementation, highlighting corporate responsibility, policy impact, and supply chain management. Industry-level analysis reveals distinct engagement patterns, with logistics and electronics sectors leading the online conversation. The six key industries also differ in their emphasis on five key topics: green manufacturing, green logistics, economic benefits, policy planning, and environmental protection and low carbon initiative. Our findings provide valuable guidance for tailoring sector-specific policy interventions to promote green supply chain management.}
}
@article{LIU2025105639,
title = {Exploring the contingent effect of cultural tailoring of GenAI chatbots on multiethnic members’ disaster information seeking and preparation attitude: A cross-group comparison},
journal = {International Journal of Disaster Risk Reduction},
volume = {126},
pages = {105639},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2025.105639},
url = {https://www.sciencedirect.com/science/article/pii/S2212420925004637},
author = {Wenlin Liu and Yan Huang and Xinyan Zhao},
keywords = {GenAl chatbots, Cultural tailoring, Disaster information seeking, Disaster preparation attitude, Multiethnic communities},
abstract = {Current research in disasters has identified significant barriers to reaching and effectively communicating disaster information with racial minorities. Cultural tailoring, a communication practice that presents information in a culturally relevant, appropriate, and appealing manner, offers great potential in customizing disaster information to meet diverse individuals’ disaster information needs. Extending existing research on cultural tailoring, the current study tests the effect of culturally tailored GenAI chatbot communication in promoting positive disaster information-seeking and coping outcomes, identifying two pathways through which cultural tailoring operates: in-group familiarity through homophily and enhanced source credibility. An experiment with 346 residents from Hispanic and African American groups living in Texas and Florida suggests that cultural tailoring effects are significantly moderated by race, and the two mediating pathways differently predict information seeking and preparation attitudes across the two groups. Results offer a more nuanced understanding of cultural tailoring in a diverse community context, providing practical guidelines for designing fair and inclusive GenAI technologies in disaster communication.}
}
@article{PUSEY2023103174,
title = {Investigating the ecological validity of second language writing assessment tasks},
journal = {System},
volume = {119},
pages = {103174},
year = {2023},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2023.103174},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X23001963},
author = {Kerry Pusey and Yuko Goto Butler},
keywords = {L2 writing assessment, Digital tools, Ecological validity, English for academic purposes, Self-assessment},
abstract = {Nowadays, writing in academic settings is mediated by digital technology in essential ways, yet many writing test tasks deny access to the digital resources common to everyday practice (e.g., spell-check, electronic dictionaries). This discrepancy potentially threatens the ecological validity of such tasks and raises questions about construct (under) representation. Informed by an ecological perspective on language and communication (van Lier, 2004), a study was carried out to better understand how access to writing resources impacts writing test task performance. Twenty-two international students enrolled in a graduate program in the United States completed two argumentative writing tasks. On one of the tasks, participants were given full access to writing resources; on the other task, no access to writing resources was given. Average scores on participants' essays were analyzed quantitatively to determine the degree to which, and in what specific domains, performance differed under each condition. In addition, participants’ self-assessments of performance on the tasks were analyzed quantitatively and qualitatively. Results suggest that writers benefitted from having access to writing resources, but the perceived impact of resource accessibility differed from the scores given by raters. These findings have implications for writing test task design and may help inform L2 writing instruction.}
}
@article{FISSEHA2025106978,
title = {Sources of resilience for refugee youth in Ethiopia: Exploring the role of education, work, community, religion, and family},
journal = {Child Abuse & Neglect},
volume = {162},
pages = {106978},
year = {2025},
note = {Advancing our understanding of violence against children: Consideration of global threats of conflict, displacement, and climate change.},
issn = {0145-2134},
doi = {https://doi.org/10.1016/j.chiabu.2024.106978},
url = {https://www.sciencedirect.com/science/article/pii/S0145213424003685},
author = {Senper Elias Fisseha and Mónica López López and Mijntje ten Brummelaar and Habtamu Wondimu Hibiso},
keywords = {Young refugees, Resilience, Socio-ecological, Mitigating factors, Ethiopia},
abstract = {Background
Young refugees' resilience is linked to involvement in socio-ecological systems that contribute to their well-being.
Objective
This study aimed to understand the experiences and factors contributing to resilience among young Sudanese and South Sudanese refugees (aged 16, M = 16 years; N = 40; 21 males, 19 females) residing at the Sherkole refugee camp in Ethiopia's Benishangul-Gumuz region.
Method
Six focus groups (N = 40) and four key informant interviews with government officials, caregivers, and school teachers explored themes related to resilience using thematic analysis. Member checking ensured findings aligned with participants' perspectives. A socio-ecological framework guided the exploration of multidimensional factors.
Results
Five themes emerged: (1) support systems, (2) work engagement, (3) access to education, (4) role of religion, and (5) community engagement. Work opportunities helped young refugees cope with challenges, but key informants raised concerns about potential risks to education. Social connection and community engagement fostered a harmonious relationship with the host community. Religion and education alleviated stress and worries. The themes interrelated – community engagement improved host community relationships, increasing job opportunities and income (leading to better support systems). Religious activities and education also benefited relationships and provided relaxation.
Conclusion
This study supports the dynamic and multi-systemic nature of resilience within a socio-ecological framework. Findings can inform future resilience-promoting interventions and policies for young refugees.}
}
@article{TOPOLE2025105804,
title = {Barriers and prospects for soil biodiversity research in the Balkans},
journal = {Applied Soil Ecology},
volume = {206},
pages = {105804},
year = {2025},
issn = {0929-1393},
doi = {https://doi.org/10.1016/j.apsoil.2024.105804},
url = {https://www.sciencedirect.com/science/article/pii/S0929139324005353},
author = {M. Topole and J. Marinko and V. Podpečan and P. Mylona and M. Debeljak},
keywords = {Soil biodiversity data, Balkan Peninsula, Data warehouse, Soil health, Soil biology publications, Research capacity},
abstract = {Soil degradation is a growing problem that threatens the well-being of humanity worldwide. One of the pillars of soil health are soil organisms, which are involved in a variety of soil processes and functions contributing to numerous ecosystem services. Although the Balkans are considered a hotspot of European biodiversity, our knowledge of soil life in this region is still limited. The Edaphobase data warehouse (https://portal.edaphobase.org/) focuses on European soil biodiversity data. The Balkan datasets in this database were analysed alongside relevant scientific literature to gain insight into soil biodiversity research and collaborative schemes in the region. In addition, assessments of national capacities for data provision and soil biodiversity research were obtained through an expert survey. The results of the study show large differences between the Balkan countries. Although Edaphobase enables metadata to accompany the soil biodiversity data, the potential of this comprehensive data warehouse for ecological modelling is largely underutilised by Balkan datasets. Responses to the questionnaire revealed significant gaps in national financial and technical capacities for soil biodiversity research, which could be addressed through an instrument that supports international collaboration via project funding. Such mechanisms would not only reduce economic disparities, but also promote cohesion within the scientific community of the region. The analysis of the network of Balkan authors revealed that collaboration between Balkan experts is currently quite unbalanced and that some countries are isolated in their research activities. This study provides a novel insight into the current state of soil biodiversity science in the Balkan countries and serves as an important reference point for a much-needed regional approach to promote soil biodiversity research in the Balkans.}
}
@article{WANG2025108011,
title = {Practice of the integration of climate change considerations into environmental impact assessment for policy in China},
journal = {Environmental Impact Assessment Review},
volume = {115},
pages = {108011},
year = {2025},
issn = {0195-9255},
doi = {https://doi.org/10.1016/j.eiar.2025.108011},
url = {https://www.sciencedirect.com/science/article/pii/S0195925525002082},
author = {Qingyang Wang and Xinyi Zhang and Jiandong Bai and Jing Wu and I-Shin Chang},
keywords = {Policy, Environmental impact assessment, Climate change, Evaluation, Mitigation, Adaptation},
abstract = {Environmental impact assessment for policy (Policy EIA) is an important and effective means to couple with climate change (CC) mitigation and adaptation during the policy-making process by systematically integrating CC considerations. As the world's largest carbon emitter and a member of the Parties of the Paris Agreement, China plays a vital role in reducing and neutralizing greenhouse gases emissions. To demonstrate the determined attitude and progressive actions to confront global warming, in China, 17 pilot Policy EIA cases were initiated from 2021 to 2023, where CC considerations are required to be integrated into Policy EIA. Adapted from the best available international practices, 22 focusing and streamlined criteria covering CC mitigation and adaptation are assembled to prudentially scrutinize CC considerations in these pilot cases. In addition, direct content analysis is applied to identify and analyze text references related to the evaluation criteria, and correlation analysis is employed to refine and validate the research findings. Overall, the results indicate that while climatic factors are considered to some extent, the integration of CC considerations into Policy EIA is in an unsatisfactory manner, with dissimilar performance across different subjects and categories. Besides, much more effort was put into mitigation consideration than into adaptation consideration. Moreover, there is a lack of applicable quantitative methodologies to measure CC impacts, while the absence of accessible, robust, and quality-assured data has become a major obstacle to CC assessment. Correspondingly, some recommendations are proposed to further improve the integration of CC considerations into Policy EIA. The research framework provides a reasonable and effective approach to evaluating the integration of CC considerations into Policy EIA, with potential applicability worldwide.}
}
@article{GONZALEZMARQUEZ2024100968,
title = {The landscape of biomedical research},
journal = {Patterns},
volume = {5},
number = {6},
pages = {100968},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100968},
url = {https://www.sciencedirect.com/science/article/pii/S266638992400076X},
author = {Rita González-Márquez and Luca Schmidt and Benjamin M. Schmidt and Philipp Berens and Dmitry Kobak},
keywords = {metascience, publications, PubMed, language models, embeddings, visualization, machine learning, gender bias, retractions},
abstract = {Summary
The number of publications in biomedicine and life sciences has grown so much that it is difficult to keep track of new scientific works and to have an overview of the evolution of the field as a whole. Here, we present a two-dimensional (2D) map of the entire corpus of biomedical literature, based on the abstract texts of 21 million English articles from the PubMed database. To embed the abstracts into 2D, we used the large language model PubMedBERT, combined with t-SNE tailored to handle samples of this size. We used our map to study the emergence of the COVID-19 literature, the evolution of the neuroscience discipline, the uptake of machine learning, the distribution of gender imbalance in academic authorship, and the distribution of retracted paper mill articles. Furthermore, we present an interactive website that allows easy exploration and will enable further insights and facilitate future research.}
}
@article{HU2025,
title = {Advances in hydrological research in China over the past two decades: Insights from advanced large language model and topic modeling},
journal = {Fundamental Research},
year = {2025},
issn = {2667-3258},
doi = {https://doi.org/10.1016/j.fmre.2025.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S266732582500216X},
author = {Jinlong Hu and Chiyuan Miao and Yi Wu and Jiajia Su},
keywords = {Hydrology, Large language models, Topic modeling, Basins, China},
abstract = {Hydrology investigates the water cycle and its relationship with the environment and societal activities, and forms the foundation for sustainable water resource management and ecological conservation. A quantitative review of hydrology aids in the scientific prediction of water resource trends, optimizing their allocation, and addressing challenges posed by climate change. However, traditional studies have lacked a systematic quantitative review of Chinese hydrology, particularly at the basin scale and across diverse research topics. Therefore, we employed advanced technologies, including large language models, regular expression techniques, and dynamic topic modeling, to conduct a quantitative analysis of hydrological research in China from 2000 to 2023 based on 289,513 hydrology-related publications. We examined the characteristics, research topics, and spatiotemporal evolution patterns of publications from China’s major basins. The results reveal a significant increase in Chinese hydrology publications (about 19 papers/year) and research collaboration (0.9 authors/decade). The soil and water assessment tool (46.7% usage), variable infiltration capacity model (15.7%), and Xinanjiang model (11.9%) were the most widely used hydrological models in Chinese research. The Yellow River, Yangtze River, and Haihe River basins received the most attention, with key research topics spanning water resources (13.9%), climate change (13.6%), and hydrological modeling (10.8%). A shift from resource-oriented studies to ecological hydrology was observed, with a growing focus on climate change and carbon dynamics. These findings reflect the evolution of Chinese hydrology from traditional water resource management to addressing contemporary environmental challenges, offering valuable insights for future research in China and globally.}
}
@article{WYATT2025103207,
title = {Safe AI for coral reefs: Benchmarking out-of-distribution detection algorithms for coral reef image surveys},
journal = {Ecological Informatics},
volume = {90},
pages = {103207},
year = {2025},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2025.103207},
url = {https://www.sciencedirect.com/science/article/pii/S157495412500216X},
author = {Mathew Wyatt and Sharyn Hickey and Ben Radford and Manuel Gonzalez-Rivero and Nader Boutros and Nikolaus Callow and Nicole Ryan and Arjun Chennu and Mohammed Bennamoun and James Gilmour},
keywords = {Safe AI, Machine learning, Deep learning, Histogram intersection, Image classification, KNN distance, Out of distribution, Coral, Benthic habitat, Interpretable AI},
abstract = {Although deep learning has demonstrated significant advances in qualitative domains, deep learning algorithms remain poor at quantifying the uncertainty of their predictions. This is especially true when applied in domains where there is data shift outside of which an algorithm has been trained. This has major implications for the use of deep learning in accurately estimating change in environmental monitoring applications. In the case of image classification for coral reef habitats, time series imagery is rarely consistent due to changing environmental conditions, differing sensors and inconsistencies in data capture, which means traditional machine learning metrics simply do not work when applied to new out of distribution datasets.1.For this reason, we benchmark the latest state-of-the-art OOD (Out Of Distribution) detection algorithms on publicly available coral reef image datasets, and evaluate histogram intersection of outlier scores as an indicator for human intervention.2.We show with a comparative analysis that the performance of OOD detection algorithms is variable, and highly dependent on in-distribution and out-of-distribution data composition. We show that KNN (K-Nearest Neighbour) distance was the most consistent across datasets, followed by Virtual-logit matching (ViM).3.This research shows a compelling example of how a handful of openly available algorithms can easily be used as a complimentary indicator alongside confidence (Softmax probability), in turn providing more efficient and safe deployment of deep learning for rapid reporting of coral reef habitats.}
}
@article{WANG2025101290,
title = {WP-MOD: A multi-omics and taxonomy database for woody plants},
journal = {Plant Communications},
volume = {6},
number = {4},
pages = {101290},
year = {2025},
issn = {2590-3462},
doi = {https://doi.org/10.1016/j.xplc.2025.101290},
url = {https://www.sciencedirect.com/science/article/pii/S2590346225000525},
author = {Qi Wang and Shaoxuan Luo and Yixiang Yang and Yawen Bai and Junrong Wei and Ke-Wang Xu and Yong Yang and Meng Li and Xiaozeng Yang and Yifan Duan and Zhonglong Guo},
keywords = {woody plants, multi-omics, taxonomy, germplasms, database},
abstract = {Woody plants, including trees, shrubs, and woody vines, are vital components of terrestrial ecosystems and are critical for maintaining biodiversity, regulating climate, and supporting human livelihoods. Over the past decade, the accumulation of high-throughput sequencing data, multi-omics data, and taxonomic information on woody plants has increased significantly, highlighting the need for an integrative database. Here, we present the Woody Plant Multi-Omics Database (WP-MOD, https://www.woodyplant.com), a comprehensive and user-friendly platform designed to meet the growing need for specialized resources in woody plant research. The WP-MOD integrates extensive taxonomic information and multi-omics data from 373 species across 35 orders and provides a centralized resource for the analysis and exploration of woody plant biology. The database includes high-quality reference genomes and reanalyzed data from RNA sequencing, small RNA sequencing, chromatin immunoprecipitation sequencing, assay for transposase-accessible chromatin sequencing, and bisulfite sequencing, along with 17 tools for sequence and omics analysis. The WP-MOD supports both genetic and molecular research and contributes to the conservation and sustainable management of woody plants. We believe that the WP-MOD will be an essential tool for plant science researchers.}
}
@article{WANG2025,
title = {Multispecies conservation corridors in China: For climate change adaptation},
journal = {Advances in Climate Change Research},
year = {2025},
issn = {1674-9278},
doi = {https://doi.org/10.1016/j.accre.2025.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1674927825001583},
author = {Pan Wang and Shu-Lin Yu and Ren-Qiang Li and Zeng-Ming Song and Jia-Quan Duan and Zhen Xu and Le-Hua Ning and Jiang-Chao Liu},
keywords = {Adaptation, Biodiversity conservation corridors, Climate change, China, Multiple species},
abstract = {The development of climate-adaptive migration corridors has emerged as a key strategy for biodiversity conservation. However, most existing studies focus on the migration patterns and adaptability of a few species and barely pay attention to the design of migration corridors that address multispecies needs at a national scale under climate change. In this study, we analysed 1023 nationally protected wildlife species in China to predict their potential distributions under current climatic conditions and the SSP2-4.5 scenario using the maximum entropy model. The projections were used as a base to conduct hotspot analysis to identify areas with declining, stable or increasing habitat selection rates (HSRs), which were designated as ecological sources. These areas correspond to regions likely to experience species emigration, retention or immigration. Using circuit theory and the minimum cumulative resistance model, we employed the Linkage Mapper tool to construct climate-resilient conservation corridors and identify critical ecological nodes. We identified 49 ecological sources, including 19 ecological sources with declining HSRs, 13 ecological sources with stable HSRs and 17 ecological sources with increasing HSRs. These HSRs collectively covered over 90% of the studied species and demonstrated a strong conservation representativeness. We also mapped 108 migration corridors, including 49 supporting species movement from areas with declining HSRs and 59 enhancing connectivity and species exchange. In addition, we identified 978 ecological pinch points and 203 barrier points, which are critical priorities for future corridor planning. A novel framework for the design of multispecies conservation corridors that support climate change adaptation, which contributes to China's efforts to achieve the Kunming–Montreal Biodiversity Framework targets and improve ecosystem connectivity.}
}
@article{MCINTYRE2025102908,
title = {Equitable writing classrooms and programs in the shadow of AI},
journal = {Computers and Composition},
volume = {75},
pages = {102908},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102908},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000847},
author = {Megan McIntyre},
keywords = {Writing programs, Equitable writing pedagogy, Writing assessment, Plagiarism, Generative AI},
abstract = {Each year, in TA orientation, in the practicum course, and in professional development sessions, I ask TAs and instructors to consider what is, for me, the key question at the heart of our work as writing teachers: what do we owe our students? And a related and equally important question: what do we owe ourselves? In 2024, just over two years into the public existence of OpenAI's ChatGPT, the contexts for these questions are perhaps more complicated than ever, but I think the answers are mostly the same: we owe our students equitable classrooms, space to try and to fail, compassion and care, and authentic engagement. We owe them the rights our discipline affirmed almost fifty years ago when CCCC adopted Students’ Right to Their Own Language as the official position of the largest organization of writing teachers in the world. This article reviews an approach to the current Generative AI moment that is rooted in these commitments and reflects an approach I call “informed refusal,” which allows us to acknowledge the existence of generative AI without requiring students to use generative AI products. We can continue to teach critical literacies and attend to the things that make first-year writing classrooms unique, especially our attention to individualized feedback on students’ writing and our attention to helping students build self-efficacy via sustainable writing processes and reflective habits of mind. At the same time, I argue against the adoption of detectors and other writing surveillance technologies because of the ways that such tools reinforce overly simplistic notions of plagiarism (Moore-Howard) and can harm our relationships with students.}
}
@article{RUI2025105115,
title = {Leveraging large language models for tourism research based on 5D framework: A collaborative analysis of tourist sentiments and spatial features},
journal = {Tourism Management},
volume = {108},
pages = {105115},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.105115},
url = {https://www.sciencedirect.com/science/article/pii/S0261517724002346},
author = {Jin Rui and Yuhan Xu and Chenfan Cai and Xiang Li},
keywords = {Online reviews, Text classification, 5D framework, Urban spatial characteristics, Large language models},
abstract = {Experience-oriented travel models have posed new demands for optimizing urban environments to promote tourism development. This study introduced a natural language classification and scoring method to explore the relationship between tourism experiences and spatial characteristics. We found that online textual data can infer and represent physical spatial features. Our findings include: (1) Tourists perceive density from moving objects, with threshold effects caused by their temporal instability. (2) Ecological and cultural-technological tourism models have varied dependencies on transportation facilities. (3) Central areas dominated by artificial functions and landscapes require more natural planning approaches to enhance the tourist experience. (4) Accessibility perceptions are influenced by driving time and proximity to the city center, rather than walking duration or the actual distance. (5) The development of a dual-network policy for buses and subways is crucial to enhance the travel experience. Our study provides evidence-based recommendations for urban renewal to improve tourism experiences.}
}
@article{DORTAGONZALEZ2024102187,
title = {Generative artificial intelligence usage by researchers at work: Effects of gender, career stage, type of workplace, and perceived barriers},
journal = {Telematics and Informatics},
volume = {94},
pages = {102187},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102187},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000911},
author = {Pablo Dorta-González and Alexis Jorge López-Puig and María Isabel Dorta-González and Sara M. González-Betancor},
keywords = {Artificial intelligence, Use of AI by researchers in the workplace, Challenges in implementing AI, Gender imbalance},
abstract = {The integration of generative artificial intelligence technology into research environments has become increasingly common in recent years, representing a significant shift in the way researchers approach their work. This paper seeks to explore the factors underlying the frequency of use of generative AI amongst researchers in their professional environments. As survey data may be influenced by a bias towards scientists interested in AI, potentially skewing the results towards the perspectives of these researchers, this study uses a regression model to isolate the impact of specific factors such as gender, career stage, type of workplace, and perceived barriers to using AI technology on the frequency of use of generative AI. It also controls for other relevant variables such as direct involvement in AI research or development, collaboration with AI companies, geographic location, and scientific discipline. Our results show that researchers who face barriers to AI adoption experience an 11 % increase in tool use, while those who cite insufficient training resources experience an 8 % decrease. Female researchers experience a 7 % decrease in AI tool usage compared to men, while advanced career researchers experience a significant 19 % decrease. Researchers associated with government advisory groups are 45 % more likely to use AI tools frequently than those in government roles. Researchers in for-profit companies show an increase of 19 %, while those in medical research institutions and hospitals show an increase of 16 % and 15 %, respectively. This paper contributes to a deeper understanding of the mechanisms driving the use of generative AI tools amongst researchers, with valuable implications for both academia and industry.}
}
@article{DU2025121237,
title = {Channel attention residual transfer learning with LLM fine-tuning for few-shot fault diagnosis in autonomous underwater vehicle propellers},
journal = {Ocean Engineering},
volume = {330},
pages = {121237},
year = {2025},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2025.121237},
url = {https://www.sciencedirect.com/science/article/pii/S0029801825009503},
author = {Wenliao Du and Xinlong Yu and Zhen Guo and Hongchao Wang and Yiyuan Gao and Ziqiang Pu and Guanghua Li and Chuan Li},
keywords = {Autonomous underwater vehicle propellers, Large language model, Transfer learning, Dual-loss nonlinear independent component estimation model, Fault diagnosis},
abstract = {Autonomous underwater vehicles (AUVs) are widely used in ocean exploration, scientific research, and other fields that perform tasks in complex underwater environments. Since propellers fault samples are very scarce and difficult to collect in AUV practice, traditional fault diagnostics face the challenge of insufficient data. For this reason, a channel attention residual transfer learning (ECRTN) model based on dual-loss nonlinear independent component estimation (DLNICE) is proposed to expand data for few-shot fault diagnosis of AUVs. Specifically, DLNICE is first used to augment fault samples by combining both time and frequency-domain information of AUV propellers vibration signals with a dual-loss function. The augmented fault samples and normal data are fed into the channel-attention residual network, which is fine-tuned by the large language model. The fine-tuned model is then used to diagnose real vibration samples in the target domain. Experimental results show that the proposed ECRTN achieves an average diagnosis accuracy of 96.81 %, outperforming other state-of-the-art fault diagnosis models for dealing with few-shot fault diagnosis tasks. The present method provides an effective technical solution for the few-shot fault diagnosis of AUV propellers and has a better prospect for practical applications.}
}
@article{ZHANG2025113454,
title = {LAMNet: Fine-grained few-shot image classification with LLM-assisted multi-modal learning for urban biodiversity monitoring},
journal = {Applied Soft Computing},
volume = {181},
pages = {113454},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113454},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625007653},
author = {Tao Zhang and Jiongchang Liu and Zeda Chen and Yeh-Cheng Chen and Mohammed Amoon and Saru Kumari and Xiaohan Liu},
keywords = {Large language model, Soft computing, Sustainable cities, Fine-grained classification, Few-shot learning, Feature optimization},
abstract = {Rapid urbanization presents significant threats to biodiversity, especially in densely populated urban areas where ecological monitoring is both imperative and challenging. Accurate identification of urban species is essential for preserving ecosystem integrity; however, existing fine-grained classification methods often struggle with limited training data and high inter-class visual ambiguity To address these challenges, we propose LAMNet, a novel framework tailored for fine-grained few-shot image classification in the context of urban biodiversity monitoring. LAMNet integrates cross-modal learning with soft computing techniques to enhance feature discrimination under limited supervision. Specifically, the LLM-Cross module fuses semantic embeddings from large language models with visual features through a multilayer perceptron, yielding richer multimodal representations. In addition, we introduce two key modules: Salient Feature Optimization (SFO), which adaptively emphasizes informative local features, and Multi-Target Information Fusion (MTIF), a multi-target augmentation strategy designed to enhance generalization from limited data. Experimental results on the CUB-200-2011 dataset demonstrate that our method achieves substantial performance gains over the baseline, with improvements of up to 8.64% in 1-shot accuracy. Furthermore, LAMNet attains a 1-shot accuracy of 87.5%, surpassing the current state-of-the-art (SOTA) methods on this benchmark. These findings underscore the efficacy of LLM-enhanced cross-modal learning in enabling robust fine-grained classification. LAMNet offers a promising tool for the identification of urban species and the assessment of biodiversity, supporting conservation planning, and contributing to sustainable urban development.}
}
@article{BENNETT2023100965,
title = {Introducing a more-than-quantitative approach to explore emerging structures of feeling in the everyday},
journal = {Emotion, Space and Society},
volume = {49},
pages = {100965},
year = {2023},
issn = {1755-4586},
doi = {https://doi.org/10.1016/j.emospa.2023.100965},
url = {https://www.sciencedirect.com/science/article/pii/S1755458623000282},
author = {Katy Bennett and Stefano {De Sabbata}}
}
@article{QIAO2024108357,
title = {The effect of novel linguistic-based review features on review helpfulness through information ecosystem and ELM theories: Heterogeneity analysis across platforms},
journal = {Computers in Human Behavior},
volume = {160},
pages = {108357},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108357},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224002255},
author = {Sun Qiao and Wu Feng},
keywords = {Online review helpfulness, Language style, Semantic association, Platform heterogeneity, Information ecology theory, ELM},
abstract = {Although online review helpfulness has been extensively discussed, examining it at the platform level can still yield new insights. Drawing on ELM and information ecosystem theories, this study identifies heterogeneity in review features and their impact on helpfulness across platforms through a multimethod analysis of 82,130 reviews on JD and TikTok. Econometric analysis revealed that reviews on mature platforms contain richer objective content, more diverse language styles, and stronger semantic associations. In terms of content, objective content diversity positively affects helpfulness on emerging platforms, while it has the opposite effect on mature platforms. Negative sentiment significantly affects helpfulness only on mature platforms, and positive sentiment has no significant effect on either platform. In terms of language style, the analysis indicated that language style diversity positively impacts the helpfulness of emerging platforms. However, four specific styles (figurative, comparative, interrogative and exaggerative) negatively affect helpfulness on emerging platforms, with only comparative style having a significant negative effect on mature platforms. In terms of semantic association, the results show a more substantial positive impact on emerging platforms. Machine learning-based performance analysis corroborates the core findings of the econometric analysis. This study provides novel findings to the existing literature and provides managerial implications for different platforms.}
}
@article{BRANTNER2025102952,
title = {Sourcing behavior and the role of news media in AI-powered search engines in the digital media ecosystem: Comparing political news retrieval across five languages},
journal = {Telecommunications Policy},
volume = {49},
number = {5},
pages = {102952},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.102952},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125000497},
author = {Cornelia Brantner and Michael Karlsson and Joanne Kuai},
keywords = {AI governance, Digital media ecosystem, Generative search engine, Large language models, News media, Sourcing},
abstract = {This study examines the role of news media in the context of generative AI-enhanced search engines, focusing on the 2024 Taiwan presidential election. Using Microsoft’s Copilot, we conducted a comparative analysis by prompting election news in five languages: English, Traditional Chinese, Simplified Chinese, German, and Swedish. While Copilot uses mainly professional news media, provides quick access to synthesized information, and exhibits source transparency, it frequently creates misinformation and misattributes news sources. The analysis highlights variations in Copilot’s sourcing behavior, showing a strong reliance on English-language sources, particularly those from the UK and US, across different prompting languages. Such reliance raises concerns about the homogenization of information and the marginalization of regional perspectives. The study underscores the critical role and dilemma of news media, which, while serving as authoritative sources in democratic societies, must navigate an increasing AI-mediated information ecosystem to maintain autonomy vis-à-vis powerful technological infrastructures. By evaluating Copilot’s sourcing practices and misinformation prevalence, this research contributes to the discourse on AI’s impact on news dissemination, media diversity, and democratic processes. Specifically, we discuss the consequences of two approaches available to news media to prevent their content from being used without compensation: opting out of crawling (“platform counterbalancing”) or establishing partnerships with AI companies. Current regulatory efforts, including copyright reforms and the EU AI Act, fall short of safeguarding journalism or regulating AI. We propose policy and regulatory recommendations to improve transparency, factual correctness, accuracy in source attribution, and accountability in AI-generated content, supporting informed citizenship in the digital age.}
}
@article{ZHONG2025,
title = {Global agricultural adaptation case database and trend analysis based on large language models},
journal = {Advances in Climate Change Research},
year = {2025},
issn = {1674-9278},
doi = {https://doi.org/10.1016/j.accre.2025.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S1674927825000747},
author = {Jing-Wen ZHONG and Xue-Yan ZHANG and Xin MA},
keywords = {Agriculture, Climate change adaptation, Large language models, ChatGPT, Natural language processing, Trend analysis},
abstract = {The Paris Agreement mandates that countries report on their adaptation efforts to evaluate the adequacy and effectiveness of these measures. Agriculture, a critical sector in climate change adaptation, benefits significantly from global case studies that provide evidence, share experiences, and disseminate knowledge. However, the rapid expansion of these case studies presents challenges in extracting and analyzing relevant information effectively. To address this, this study developed a question‒answering information extraction framework that combines geographic analysis with ChatGPT. Guided by the Systematic Evidence Synthesis (ROSES) review protocol, we established a comprehensive global database of agricultural adaptation cases from 2000 to 2024. This database includes key information such as case distribution, climate stressors, adaptation measures, cost-effectiveness, and constraints, aimed at identifying major trends in agricultural adaptation. Our findings reveal the following: 1) Natural language processing technologies, particularly Large Language Models (LLMs), greatly enhance the efficiency and depth of extracting key information from adaptation cases. This advancement supports the frequent updating of the agricultural adaptation database. 2) There is a notable geographic imbalance in agricultural adaptation efforts globally. Adaptation cases are concentrated in central and southern Africa, southern Asia, Europe, and other regions. While there is diversity in responses to slow onset events, measures for extreme climate events are less common, indicating a gap in the sector's ability to address sudden and uncertain challenges. 3) Agricultural adaptation measures are evolving from individual technologies to more comprehensive approaches. The shift is from methods like crop improvement and irrigation adjustments to integrated measures such as climate-smart agriculture, conservation agriculture, and sustainable practices. These approaches collectively enhance adaptation capacity through technological, managerial, infrastructural, and biodiversity improvements, reflecting a deeper understanding and ongoing refinement of adaptation practices. This study highlights the significant potential of LLMs in improving the efficiency of information extraction and analysis for global adaptation research. It offers new methods for quickly summarizing adaptation cases in agriculture and potentially other fields, providing valuable insights and recommendations for global agricultural policymakers.}
}
@article{ANDERSON2024100097,
title = {Analyzing public sentiment on sustainability: A comprehensive review and application of sentiment analysis techniques},
journal = {Natural Language Processing Journal},
volume = {8},
pages = {100097},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100097},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000451},
author = {Tess Anderson and Sayani Sarkar and Robert Kelley},
keywords = {Sentiment analysis, Sustainability initiatives, Machine learning, Deep learning, Natural language processing, Social media analysis, Public opinion mining},
abstract = {In the contemporary context of escalating environmental concerns, understanding public sentiment toward sustainability initiatives is crucial for shaping effective policies and practices. This research explores the efficacy of sentiment analysis in mining social media data to gauge public attitudes toward sustainability efforts. This study employs a variety of machine learning and deep learning models to perform sentiment analysis utilizing a dataset comprising tweets related to human perception towards environmental sustainability. The aim is to transform unstructured social media text into structured sentiment scores. The comparative analysis includes pre-trained sentiment analysis models like VADER, TextBlob, and Flair with traditional machine learning models such as Logistic Regression, SVM, Decision Tree, Naive Bayes, Random Forest, alongside advanced deep learning techniques like LSTM and pre-trained models BERT and GPT-2. Our results reveal significant variations in model performance, underscoring the importance of selecting appropriate sentiment analysis tools that align with the nuanced domain of sustainability. The study further emphasizes the role of transparent and reproducible research practices in advancing trustworthy AI applications. By providing insights into public opinions on sustainability, this research contributes to the broader discourse on leveraging AI to foster environmental responsibility and action. This work not only illustrates the potential of sentiment analysis in understanding public discourse but also highlights the critical need for tailored approaches that consider the specificity of the sustainability context.}
}
@article{HUANG2024e35190,
title = {Framework restoration on Tang Dynasty garden as a multiple-histories environment: Regions, ecology, architecture, and human behavior},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e35190},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35190},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024112212},
author = {Biyu Huang and Zhenwei Zhang and Wende Chen},
keywords = {Tang dynasty garden, Feature framework, Restoration, Risk factors, Protective factors},
abstract = {From a multiple-histories perspective, this paper attempts to restore the feature framework of Tang Dynasty gardens by describing the environment panorama of that era. Tang Dynasty gardens have their own unique and complex environment features, which is crucial for understanding Chinese classical gardens. This research developed a massive text mining method of historical-document to detect all garden-related elements in Tang poetry. By sorting out these elements, it has been restored the original appearance of Tang Dynasty gardens and summarized its feature framework. The resulting model included 199 factors, 173 of which are correlating with gardens. Among the 173 factors, 129 are risk factors and 44 are protective factors. This paper restores the feature framework of Tang Dynasty gardens from the following four points, namely regions, ecology, architecture and human behavior. Understanding the Tang Dynasty gardens would help understand the development context of Chinese classical gardens, and should provide new paths for contemporary environment creation.}
}
@article{DUBOURG2025100930,
title = {DEEP: A model of gaming preferences informed by the hierarchical nature of goal-oriented cognition},
journal = {Entertainment Computing},
volume = {53},
pages = {100930},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2025.100930},
url = {https://www.sciencedirect.com/science/article/pii/S1875952125000102},
author = {Edgar Dubourg and Valérian Chambon},
keywords = {Video games, Play, Agency, Preferences, Goal-directed action, Hierarchy},
abstract = {Video game design and player engagement revolve around the concept of agency, which refers to the ability to shape one’s environment through personal choices and actions. However, different types of agentive experiences can be distinguished according to the nature of the agent’s goal. Recent models of voluntary action suggest that goals are organized hierarchically. In this paper, we test the ability of these models to explain variability in gaming preferences. First, we performed a factor analysis on game-related actions that participants ( N = 750) were asked to rate on an interest scale. We found that game preferences varied along 4 dimensions organized along gradients of goal abstraction and exploration (Discovering, Experimenting, Expanding, Performing, or DEEP dimensions). We then automatically annotated video games ( N = 16,000) on each of these dimensions and tested the hierarchical structure of goal-directed actions in video games. Finally, in a pre-registered study ( N = 1000), we show that the DEEP dimensions predict participants’ preferred video games and correlate with expected psychological factors. We suggest that this research can help improve existing taxonomies of videogame types, better understand player preferences, and refine the relationship between game design and human psychology.}
}
@article{AFFINITO2025101726,
title = {Towards a unified ontology for monitoring ecosystem services},
journal = {Ecosystem Services},
volume = {73},
pages = {101726},
year = {2025},
issn = {2212-0416},
doi = {https://doi.org/10.1016/j.ecoser.2025.101726},
url = {https://www.sciencedirect.com/science/article/pii/S2212041625000300},
author = {F. Affinito and J.M. Holzer and M.-J. Fortin and A. Gonzalez},
keywords = {Ecosystem services monitoring, Interoperability, Ontology, Semantics, Ecosystem service conceptualisation},
abstract = {Ecosystem services (ES) are an important part of global and national environmental policies. In this context, there is a call for the monitoring of ES to support their management. However, the proliferation of terms used within ES science is a barrier to standardised monitoring. Monitoring ES requires knowing exactly what variables to measure and how they relate to change in the states of ES. It further requires interoperability between methodologies used by information systems to operationalise data flows. Here, we aim to systematise the language used to define ES and the terminology used in their monitoring by developing an ontology for ES monitoring. Ontologies are tools that operationalise concepts and the relationships among terms used to define them. An ontology allows people and machines to use terms consistently. Building on advances in other disciplines, the ES monitoring ontology systematises the language of ES across major conceptual frameworks advancing conceptual clarity and operationalisation of ES. We test the ES monitoring ontology with data from three ES in British Columbia, Canada, to highlight how it can enable information sharing and monitoring. We show that the ontology can organise and retrieve information and data for ES monitoring in a systematic way. Our work contributes to advancing interoperability of ES, taking a step towards systematically understanding ES change with automated tools. We invite members of the ES community to join the effort of developing this ontology for ES so that can it contribute to the challenge of systematically monitoring change in social-ecological systems.}
}
@article{CHEN2024181,
title = {Chat3D: Interactive understanding 3D scene-level point clouds by chatting with foundation model for urban ecological construction},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {212},
pages = {181-192},
year = {2024},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2024.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0924271624001849},
author = {Yiping Chen and Shuai Zhang and Ting Han and Yumeng Du and Wuming Zhang and Jonathan Li},
keywords = {Point cloud understanding, Large language model interact, Urban ecological construction, Prompt engineering, Thought chain},
abstract = {With the artificial intelligence technology development boom, large language models are demonstrating their potential in comprehension and creativity. Large language models such as GPT-4 and Gemini have been able to powerfully study for various professional-level exams. However, as a language model itself, its powerful comprehension can only be reflected in text sequences. Currently, although videos can be generated through the connection between 3D point clouds and large language models, there is currently no prompt project that directly interacts with one-dimensional through attribute calculation results. The point cloud data is also rich in information that can support various tasks of urban construction. For scene-level point cloud data, there has been a lot of research done on semantic segmentation, target detection, and other tasks. However, it is usually difficult to provide direct help to scene construction from the perception results. This paper presents a method for applying large language models to urban ecological construction by combining the results of 3D point cloud semantic segmentation. The objective is to integrate the prior knowledge and creative capabilities of Large Language Models (LLMs) within urban development with the outcomes derived from point cloud semantic segmentation results. This integration aims to establish an interactive point cloud intelligent analysis system, tailored for aiding decision-making processes in urban ecological civilization construction, thus presenting innovative perspectives for the advancement of smart city development.}
}
@article{CASTRO2024102742,
title = {Large language models overcome the challenges of unstructured text data in ecology},
journal = {Ecological Informatics},
volume = {82},
pages = {102742},
year = {2024},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2024.102742},
url = {https://www.sciencedirect.com/science/article/pii/S157495412400284X},
author = {Andry Castro and João Pinto and Luís Reino and Pavel Pipek and César Capinha},
keywords = {AI, Automation, Data integration, GPT, LLaMA, Unstructured data},
abstract = {The vast volume of currently available unstructured text data, such as research papers, news, and technical report data, shows great potential for ecological research. However, manual processing of such data is labour-intensive, posing a significant challenge. In this study, we aimed to assess the application of three state-of-the-art prompt-based large language models (LLMs), GPT-3.5, GPT-4, and LLaMA-2-70B, to automate the identification, interpretation, extraction, and structuring of relevant ecological information from unstructured textual sources. We focused on species distribution data from two sources: news outlets and research papers. We assessed the LLMs for four key tasks: classification of documents with species distribution data, identification of regions where species are recorded, generation of geographical coordinates for these regions, and supply of results in a structured format. GPT-4 consistently outperformed the other models, demonstrating a high capacity to interpret textual data and extract relevant information, with the percentage of correct outputs often exceeding 90% (average accuracy across tasks: 87–100%). Its performance also depended on the data source type and task, with better results achieved with news reports, in the identification of regions with species reports and presentation of structured output. Its predecessor, GPT-3.5, exhibited slightly lower accuracy across all tasks and data sources (average accuracy across tasks: 81–97%), whereas LLaMA-2-70B showed the worst performance (37–73%). These results demonstrate the potential benefit of integrating prompt-based LLMs into ecological data assimilation workflows as essential tools to efficiently process large volumes of textual data.}
}
@article{WANG2025100604,
title = {Leveraging scenario differences for cross-task generalization in water plant transfer machine learning models},
journal = {Environmental Science and Ecotechnology},
volume = {27},
pages = {100604},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2025.100604},
url = {https://www.sciencedirect.com/science/article/pii/S2666498425000821},
author = {Yu-Qi Wang and Xiao-Qin Luo and Han-Bo Zhou and Jia-Ji Chen and Wan-Xin Yin and Yun-Peng Song and Hao-Bo Wang and Bai Yu and Yu Tao and Hong-Cheng Wang and Ai-Jie Wang and Nan-Qi Ren},
keywords = {Urban water system, Model generalization, Transfer learning, Wastewater treatment, Drinking water treatment},
abstract = {Machine learning (ML) models are increasingly deployed in urban water systems to optimize operations, enhance efficiency, and curb resource consumption amid growing sustainability demands. Yet, their transferability across plants is hampered by scenario differences—variations in environmental factors, protocols, and data distributions—that erode performance and necessitate energy-intensive retraining. While existing strategies focus on minimizing these differences via domain adaptation or fine-tuning, none exploit them as inherent prior knowledge for improved generalization. Here we show an environmental information adaptive transfer network (EIATN) framework that can leverage scenario differences to enable effective generalization across distinct prediction tasks within the same water plant. By evaluating EIATN across four scenario categories and 16 diverse ML architectures—yielding 64 models in total—we demonstrate its feasibility, with bidirectional long short-term memory emerging as the top performer, achieving a mean absolute percentage error of just 3.8 % while requiring only 32.8 % of the typical data volume. In a case study of Shenzhen's urban water system, it reduced carbon emissions by 40.8 % compared to fine-tuning and 66.8 % relative to direct modeling from scratch. EIATN unlocks the reuse of vast existing ML models in water systems, yielding substantial energy savings and fostering equitable, low-carbon intelligent management.}
}
@article{WANG2025145547,
title = {Predicting dissolved oxygen in water areas using transfer learning and visual information from real-time surveillance videos},
journal = {Journal of Cleaner Production},
volume = {507},
pages = {145547},
year = {2025},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2025.145547},
url = {https://www.sciencedirect.com/science/article/pii/S0959652625008972},
author = {Jihong Wang and Yituo Zhang and Chaolin Li and Hengpan Duan and Wenhui Wang},
keywords = {Water quality monitoring, Transfer learning, Surveillance videos, Dissolved oxygen, Convolutional neural network},
abstract = {Effective management of sudden water pollution incidents (SWPI) requires real-time water quality monitoring, yet existing solutions based on Internet-of-Things (IoT) sensors face persistent challenges regarding sensor deployment costs and maintenance. This study proposes a novel data-driven method leveraging surveillance camera networks to monitor water quality. A case study was conducted on a river in southern China using dissolved oxygen (DO) as a proof-of-concept output, where data from three monitoring stations were used. A convolutional neural network using transfer learning and fine-tuning demonstrated superior performance (R2 = 0.80 ± 0.01) compared to conventional feature engineering methods (R2 = 0.13–0.63), with cross-station validation confirming model generalizability (Station Ⅱ: 0.77, Station Ⅲ: 0.87). Interpretive saliency mapping revealed the model's capacity to extract the color, edge, and texture features in the images, which revealed the effect of water color, suspended substance (SS), flow rate on DO. The findings demonstrate the novel data-driven method based on visual information from widely distributed cameras to predict DO, which is expected to significantly inspire the technological evolution of water quality monitoring.}
}
@article{MA2024108852,
title = {Metagenome comparison (MC): A new framework for detecting unique/enriched OMUs (operational metagenomic units) derived from whole-genome sequencing reads},
journal = {Computers in Biology and Medicine},
volume = {180},
pages = {108852},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108852},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524009375},
author = {Zhanshan (Sam) Ma},
keywords = {Metagenome comparison (MC) framework, Operational metagenomic unit (OMU), Unique metagenomic genes, Enriched metagenomic genes, OMU specificity (OS), OMU specificity diversity (OSD), Metagenomic gene (MG), Metagenome functional gene cluster (MFGC), Metagenome function/pathway (MF/MP)},
abstract = {Background
Current methods for comparing metagenomes, derived from whole-genome sequencing reads, include top-down metrics or parametric models such as metagenome-diversity, and bottom-up, non-parametric, model-free machine learning approaches like Naïve Bayes for k-mer-profiling. However, both types are limited in their ability to effectively and comprehensively identify and catalogue unique or enriched metagenomic genes, a critical task in comparative metagenomics. This challenge is significant and complex due to its NP-hard nature, which means computational time grows exponentially, or even faster, with the problem size, rendering it impractical for even the fastest supercomputers without heuristic approximation algorithms.
Method
In this study, we introduce a new framework, MC (Metagenome-Comparison), designed to exhaustively detect and catalogue unique or enriched metagenomic genes (MGs) and their derivatives, including metagenome functional gene clusters (MFGC), or more generally, the operational metagenomic unit (OMU) that can be considered the counterpart of the OTU (operational taxonomic unit) from amplicon sequencing reads. The MC is essentially a heuristic search algorithm guided by pairs of new metrics (termed MG-specificity or OMU-specificity, MG-specificity diversity or OMU-specificity diversity). It is further constrained by statistical significance (P-value) implemented as a pair of statistical tests.
Results
We evaluated the MC using large metagenomic datasets related to obesity, diabetes, and IBD, and found that the proportions of unique and enriched metagenomic genes ranged from 0.001% to 0.08 % and 0.08%–0.82 % respectively, and less than 10 % for the MFGC.
Conclusion
The MC provides a robust method for comparing metagenomes at various scales, from baseline MGs to various function/pathway clusters of metagenomes, collectively termed OMUs.}
}
@article{CHAPELLE2025103672,
title = {Generative AI as game changer: Implications for language education},
journal = {System},
volume = {132},
pages = {103672},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103672},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X2500082X},
author = {Carol A. Chapelle},
keywords = {GenAI, Artificial intelligence, Language pedagogy, Language assessment, Second language acquisition, Language teacher education, Technology, Technology-mediated language learning},
abstract = {This paper explores the new parameters of technology in applied linguistics in view of today's open access to generative AI (GenAI) that can create grammatical language in response to users' prompts. I examine GenAI in language education by first situating it within the steady progression of changes brought by evolving technologies. Then, four areas of change in applied linguistics are identified: language pedagogy, language assessment, second language acquisition, and language teacher education. I make connections between the concepts and methods associated with each area for technology-related research and practice, and suggest extensions prompted by GenAI. For example, in language pedagogy and assessment GenAI offers new tools for providing input to learners, corrective feedback, and opportunities for interaction. The study of second language acquisition can be enhanced through observation of GenAI's linguistic performance and the study of the theory of language processing in artificial intelligence. These areas are relevant to language teacher education, and therefore need to be taken into account in the definition of teachers' technological pedagogical content knowledge (TPACK), which in turn helps to define components of GenAI literacy relevant to the field.}
}
@article{VETTER2024102831,
title = {Towards a framework for local interrogation of AI ethics: A case study on text generators, academic integrity, and composing with ChatGPT},
journal = {Computers and Composition},
volume = {71},
pages = {102831},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102831},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000070},
author = {Matthew A. Vetter and Brent Lucia and Jialei Jiang and Mahmoud Othman},
keywords = {Artificial intelligence (AI), Academic integrity, Text generators, academic policy, Composition pedagogy, Ethics},
abstract = {Ethical frameworks for text generators (TGs) in education are generally concerned with personalized instruction, a dependency on data, biases in training data, academic integrity, and lack of creativity from students. While broad-level, institutional guidelines provide value in understanding the ethical dimensions of artificial intelligence (AI) for the classroom, there is a need for a more ecological understanding of how AI ethics might be constructed locally, one that takes into account the negotiation of AI between teacher and student. This article investigates how an educational ethical framework for AI use emerges through a qualitative case study of one composition student's interaction with and understanding of using ChatGPT as a type of writing partner. Analysis of interview data and student logs uncover what we term an emergent “local ethic” – a framework that is capable of exploring unique ethical considerations, values, and norms that develop at the most foundational unit of higher education – the individual classroom. Our framework is meant to provide a heuristic for other writing teacher-scholars as they interrogate issues related to pedagogy, student criticality, agency, reliability, and access within the context of powerful AI systems.}
}
@article{SOOMRO2024131129,
title = {How effective is twitter (X) social media data for urban flood management?},
journal = {Journal of Hydrology},
volume = {634},
pages = {131129},
year = {2024},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2024.131129},
url = {https://www.sciencedirect.com/science/article/pii/S0022169424005249},
author = {Shan-e-hyder Soomro and Muhammad Waseem Boota and Haider M. Zwain and Gul-e-Zehra Soomro and Xiaotao Shi and Jiali Guo and Yinghai Li and Muhammad Tayyab and Mairaj Hyder Alias {Aamir Soomro} and Caihong Hu and Chengshuai Liu and Yuanyang Wang and Junaid Abdul Wahid and Yanqin Bai and Sana Nazli and Jia Yu},
keywords = {Artificial intelligence (AI), Large language model (LLM), Natural language processiong (NLP), Resilience, Sentiment analysis (SA), Urban flood},
abstract = {Social media has been an instant source of information for natural disasters, such as urban floods, throughout the world. Ex-post evaluation of the information is considered more important after a flood disaster with devastating consequences on critical infrastructure, the environment, and the well-being of the society. Research proposes an evaluation framework for integrating the disorganized online public opinion on urban flood disaster events towards emotional and conceptual characteristics for better ex-post analysis and public participation. Social media posts on an urban flood were acquired using a search engine, and then sentiment analysis, topic modeling, and spatial–temporal analysis were performed to generate measures of online public opinion about the urban flood crisis. Twitter (X) is the most popular microblogging service presently available. As per the methodology, we analyzed all tweets regarding the 2022 urban flood in the cosmopolitan city (Karachi) of Pakistan from users all over the world. The evaluation results demonstrated that the distribution patterns of post intensities and emotion polarity in response to the floods emphasized crucial aspects with contradictory emotions and highlighted the strategic implications. Experimental results on real datasets show relatively better performance than the baseline and state-of-the-art approaches and achieved the highest 91% score. Online public opinion is a valuable supplement to ex post-disaster evaluation as it helps the project (e.g., flood management) better perform and provides suggestions for future flood mitigation, especially public participation management.}
}
@article{TANG2025137930,
title = {Decoding carbon information disclosure with NLP techniques: Combating carbonwashing for energy and climate transition},
journal = {Energy},
volume = {335},
pages = {137930},
year = {2025},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2025.137930},
url = {https://www.sciencedirect.com/science/article/pii/S0360544225035728},
author = {Pengcheng Tang and Guolin Wang and Jinwei Wang and Hao Tian},
keywords = {Carbon information disclosure, Carbonwashing, Text mining, Energy and climate transition},
abstract = {Amid the pressing need for carbon information disclosure (CID) and the widespread issue of "carbonwashing" in the process of energy and climate transition, our study comprehensively deconstructs CID from the perspectives of completeness, consistency, readability, and tone. Utilizing a sample of 8578 firms that publish social and environmental responsibility reports, our empirical investigation leverages a suite of natural language processing techniques, including the Doc2Vec algorithm and BERT model, alongside econometric methods such as seemingly unrelated regression and Heckman selection. Our analysis reveals several key findings: firms engaging in CID exhibit selective disclosure, weak consistency and readability, and a marked preference for positive language. There exists limited interrelation between completeness and other CID features, which does not significantly strengthen even with improvements in the external information environment. Our paper not only advances the understanding of how to quantify CID performance but also has significant practical implications for promoting CID quality and addressing "carbonwashing" in China and possibly in other emerging countries where third-party carbon information is lacking.}
}
@article{EHMKE2025222,
title = {Self-perceived knowledge, skills, and attitude of nursing faculty on generative artificial intelligence in nursing education: A descriptive, cross-sectional study},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {3},
pages = {222-227},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725000447},
author = {Sabrina D. Ehmke and Jenny Bridges and Sarah E. Patel},
keywords = {Artificial intelligence, Nursing education, Nursing faculty},
abstract = {Background
AI is transforming health and education, offering innovative solutions to workflow and curriculum challenges. However, faculty members lack familiarity with AI, limiting their ability to prepare students for AI-driven healthcare.
Aim
Our study investigated nursing faculty's knowledge, skills, and attitudes toward integrating Artificial Intelligence (AI) into education, examining differences by degree type and the influence of policies or syllabi on AI integration.
Methods
A descriptive, cross-sectional study assessed faculty's self-perceptions of knowledge, skills, and attitudes regarding AI in education. Data were gathered via a survey of nursing faculty from diverse institutions.
Results
Findings revealed gaps in AI knowledge and skills linked to educational level and institutional policy development. Doctorly prepared-faculty reported higher perceived knowledge and skills, while BS-prepared faculty had higher attitudes toward AI. Faculty involved in AI policy or syllabus development perceived greater knowledge, skills, and attitudes.
Conclusion
Faculty education and policy support are critical for integrating AI into education. Institutions should invest in faculty development and ethical AI adoption, using case studies, simulation, and decision-support tools to enhance curriculum and healthcare outcomes.}
}
@article{TLEUKEN2025125324,
title = {Designing a stakeholder engagement framework with critical success factors for Hubs for Circularity},
journal = {Journal of Environmental Management},
volume = {384},
pages = {125324},
year = {2025},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2025.125324},
url = {https://www.sciencedirect.com/science/article/pii/S0301479725013003},
author = {Aidana Tleuken and Patricia Rogetzer and Luca Fraccascia and Devrim Murat Yazan},
keywords = {Hubs for Circularity, Industrial symbiosis, Circular economy, Socio-economic sustainability indicators, Stakeholder engagement},
abstract = {This paper introduces a framework aimed at evaluating stakeholder involvement within Hubs for Circularity (H4C), which play a critical role in advancing the circular economy. It demonstrates the significance of collaboration among stakeholders and the need for a structured approach to assess the effectiveness of H4C initiatives. As a result of the literature review synthesis, the paper proposes a novel and actionable framework for stakeholder engagement. It is composed of several key elements: it begins with the identification and analysis of the different stakeholder groups participating in H4C projects. Next, it advocates for a comprehensive review of the factors influencing H4C implementation through an analysis of drivers, barriers, and enablers. It also emphasizes the development of success criteria aligned with the Sustainable Development Goals to measure the outcomes of H4C initiatives. The paper concludes by proposing future research directions, such as integrating the Societal Readiness Level and utilizing social network analysis and regional input–output modeling to assess the socio-economic impacts of H4C projects. Overall, the paper highlights the critical role of stakeholder engagement and effective evaluation frameworks in the success of H4C initiatives and the advancement of sustainability goals.}
}
@article{LI2025103617,
title = {“Navigating Precarity”: Motivation of English language teachers in a Chinese higher vocational college},
journal = {System},
volume = {130},
pages = {103617},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103617},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25000272},
author = {Luyao Li and Yingshan Hu},
keywords = {Motivation, English language teacher, Higher vocational college, Ecological systems theory, Possible language teacher self},
abstract = {This study examines the motivation of English language teachers (ELTers) in a higher vocational college in southeast China. Although teacher motivation has attracted growing academic attention, much of the existing literature adopts reductionist approaches, categorising motivation into fixed types rather than embracing a holistic and ecological perspective. Furthermore, non-degree vocational college English teachers remain an underexplored group in this field. In response, this study utilises Bronfenbrenner's ecological systems theory (1979) alongside the Possible Language Teacher Self theory (Kubanyiova, 2009) to explore the motivation of higher vocational college ELTers through life-story narratives. Data were collected from two female ELTers using multiple sources, including life-story interviews, follow-up interviews, and WeChat chat logs and Moments. The findings offer a nuanced perspective on ELTers' motivation, highlighting its dynamic nature as an interaction between individual agency and broader contextual forces. This study emphasises the need to move beyond simplistic conceptualisations and advocates for comprehensive support measures for higher vocational college ELTers. The insights contribute to the broader discourse on teacher motivation and have significant implications for educational policies on teacher retention across various levels and disciplines.}
}
@article{ZHANG2024128455,
title = {Perception study of urban green spaces in Singapore urban parks: Spatio-temporal evaluation and the relationship with land cover},
journal = {Urban Forestry & Urban Greening},
volume = {99},
pages = {128455},
year = {2024},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2024.128455},
url = {https://www.sciencedirect.com/science/article/pii/S161886672400253X},
author = {Wenting Zhang and Yuxin Su},
keywords = {Land cover, Landscape perception, Large language model, Sentiment analysis, Urban green spaces},
abstract = {In the current era of increasing urbanization, urban green spaces play a crucial role in enhancing human well-being. However, quantifying public perceptions from text data at spatio-temporal scales remains challenging, and the relationship between urban green space perception and spatial-physical attributes requires further exploration. This study systematically examines public perceptions of urban green spaces within Singapore's urban parks from 2018 to 2022. Utilizing Twitter data, it applies large language models to conduct textual content analysis related to urban green space. The findings reveal a positive trend, with individuals expressing favorable perceptions and satisfaction towards urban green spaces in Singapore. Specifically, this study demonstrates that people's perceptions of urban green spaces are influenced by vegetation density. Higher vegetation density heightens people's awareness of spatial presence, while shrub and grassland may lead to neglect of urban green spaces as individuals focus more on themselves. Additionally, due to the spatial heterogeneity of the area, there is no clear correlation between all land covers and public satisfaction with urban green spaces in Singapore. The results also indicate a significant decrease in public perception in 2020, followed by a subsequent recovery. This fluctuation is attributed to the substantial impact of the COVID-19 pandemic, suggesting that external socio-political, economic, and public health events can impact public green space needs and spatial perceptions. In conclusion, this study contributes to the understanding of urban green spaces by effectively analyzing textual content extracted from social media data using large language models. The insights gained contribute valuable to the following discussions regarding the planning and design of urban green spaces and urban parks.}
}
@article{LIGHT2025101669,
title = {Applying the science impact framework to understand real-world applications and impacts of ICESat and ICESat-2 data on decision-making},
journal = {Remote Sensing Applications: Society and Environment},
volume = {39},
pages = {101669},
year = {2025},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2025.101669},
url = {https://www.sciencedirect.com/science/article/pii/S2352938525002228},
author = {Siobhan L. Light and Molly E. Brown and Aimee R. Neeley and Thomas A. Neumann},
keywords = {ICESat, ICESat-2, Remote sensing, Laser altimetry, Science impact, Science applications, Climate change},
abstract = {Assessing the societal impact of satellite remote sensing datasets is essential to understanding how these data influence decision-making and to identifying opportunities for further engagement. However, measuring such impacts remains challenging for missions serving diverse stakeholder communities. In this study, we evaluate the broader impact of NASA's Ice, Cloud, and land Elevation Satellite (ICESat) and its successor mission, ICESat-2 by adapting the scientific impact framework (SIF), originally developed to assess public health research, into an Earth science-specific version (e-SIF). This framework captures data dissemination, community awareness, data-driven actions, measurable changes, and future influence, moving beyond traditional academic metrics to assess the missions' reach and effectiveness. Our findings reveal extensive global usage of ICESat and ICESat-2 data, with applications including, but not limited to, shallow water bathymetry, climate mitigation strategies, and forest management. By comparing the prevalence of topical areas in academic literature to real-world applications, we found that althoughthe cryosphere is the most frequently studied domain, differences between research focus and practical use highlight potential areas where further research could better support stakeholders. We found that ICESat and ICESat-2 data are widely employed by national and international governmental and non-governmental organizations but found only limited use by private sector and local governments. We recommend that the ICESat-2 Applications Team expand outreach efforts to these sectors to enhance dissemination of mission data. Furthermore, numerous ICESat-2 applications benefit from long-term data continuity, reinforcing the need for a successor mission. This study demonstrates the feasibility to use e-SIF to evaluate the impact of Earth science missions.}
}
@article{BENJIRA2025102405,
title = {Automated mapping between SDG indicators and open data: An LLM-augmented knowledge graph approach},
journal = {Data & Knowledge Engineering},
volume = {156},
pages = {102405},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102405},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24001290},
author = {Wissal Benjira and Faten Atigui and Bénédicte Bucher and Malika Grim-Yefsah and Nicolas Travers},
keywords = {Sustainable Development Goals (SDG), Large language model (LLM), Knowledge graph (KG), Open data, Schema mapping},
abstract = {Meeting the Sustainable Development Goals (SDGs) presents a large-scale challenge for all countries. SDGs established by the United Nations provide a comprehensive framework for addressing global issues. To monitor progress towards these goals, we need to develop key performance indicators and integrate and analyze heterogeneous datasets. The definition of these indicators requires the use of existing data and metadata. However, the diversity of data sources and formats raises major issues in terms of structuring and integration. Despite the abundance of open data and metadata, its exploitation remains limited, leaving untapped potential for guiding urban policies towards sustainability. Thus, this paper introduces a novel approach for SDG indicator computation, leveraging the capabilities of Large Language Models (LLMs) and Knowledge Graphs (KGs). We propose a method that combines rule-based filtering with LLM-powered schema mapping to establish semantic correspondences between diverse data sources and SDG indicators, including disaggregation. Our approach integrates these mappings into a KG, which enables indicator computation by querying graph’s topology. We evaluate our method through a case study focusing on the SDG Indicator 11.7.1 about accessibility of public open spaces. Our experimental results show significant improvements in accuracy, precision, recall, and F1-score compared to traditional schema mapping techniques.}
}
@article{WIECZOREK2025103537,
title = {The Bot Delusion. Large language models and anticipated consequences for academics’ publication and citation behavior},
journal = {Futures},
volume = {166},
pages = {103537},
year = {2025},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103537},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724002209},
author = {Oliver Wieczorek and Isabel Steinhardt and Rebecca Schmidt and Sylvi Mauermeister and Christian Schneijderberg},
keywords = {Large Language Models, Matthew Effect, Academic Publishing and Citation Systems, Scientific Norms, Thought Experiment},
abstract = {The present paper discusses the extent to which Large Language Models (LLMs) may affect the scientific enterprise, reinforcing or mitigating existing structural inequalities expressed by the Matthew Effect and introducing a “bot delusion” in academia. In a theory-led thought experiment, we first focus on the academic publication and citation system and develop three scenarios of the anticipated consequences of using LLMs: reproducing content and status quo (Scenario 1), enabling content coherence evaluation (Scenario 2) and content evaluation (Scenario 3). Second, we discuss the interaction between the use of LLMs and academic (counter)norms for citation selection and their impact on the publication and citation system. Finally, we introduce communal counter-norms to capture academics’ loyal citation behavior and develop three future scenarios that academia may face when LLMs are widely used in the research process, namely status quo future of science, mixed-access future, and open science future.}
}
@article{BERGER2024106003,
title = {Towards reusable building blocks for agent-based modelling and theory development},
journal = {Environmental Modelling & Software},
volume = {175},
pages = {106003},
year = {2024},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2024.106003},
url = {https://www.sciencedirect.com/science/article/pii/S1364815224000641},
author = {Uta Berger and Andrew Bell and C. Michael Barton and Emile Chappin and Gunnar Dreßler and Tatiana Filatova and Thibault Fronville and Allen Lee and Emiel {van Loon} and Iris Lorscheid and Matthias Meyer and Birgit Müller and Cyril Piou and Viktoriia Radchuk and Nicholas Roxburgh and Lennart Schüler and Christian Troost and Nanda Wijermans and Tim G. Williams and Marie-Christin Wimmler and Volker Grimm},
keywords = {Individual-based modelling, Theory development, Complex adaptive systems, Software engineering, Best practices},
abstract = {Despite the increasing use of standards for documenting and testing agent-based models (ABMs) and sharing of open access code, most ABMs are still developed from scratch. This is not only inefficient, but also leads to ad hoc and often inconsistent implementations of the same theories in computational code and delays progress in the exploration of the functioning of complex social-ecological systems (SES). We argue that reusable building blocks (RBBs) known from professional software development can mitigate these issues. An RBB is a submodel that represents a particular mechanism or process that is relevant across many ABMs in an application domain, such as plant competition in vegetation models, or reinforcement learning in a behavioural model. RBBs need to be distinguished from modules, which represent entire subsystems and include more than one mechanism and process. While linking modules faces the same challenges as integrating different models in general, RBBs are “atomic” enough to be more easily re-used in different contexts. We describe and provide examples from different domains for how and why building blocks are used in software development, and the benefits of doing so for the ABM community and to individual modellers. We propose a template to guide the development and publication of RBBs and provide example RBBs that use this template. Most importantly, we propose and initiate a strategy for community-based development, sharing and use of RBBs. Individual modellers can have a much greater impact in their field with an RBB than with a single paper, while the community will benefit from increased coherence, facilitating the development of theory for both the behaviour of agents and the systems they form. We invite peers to upload and share their RBBs via our website - preferably referenced by a DOI (digital object identifier obtained e.g. via Zenodo). After a critical mass of candidate RBBs has accumulated, feedback and discussion can take place and both the template and the scope of the envisioned platform can be improved.}
}
@article{MA2025101178,
title = {Navigating parasitic strategy},
journal = {Organizational Dynamics},
pages = {101178},
year = {2025},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2025.101178},
url = {https://www.sciencedirect.com/science/article/pii/S0090261625000555},
author = {Hao Ma and Mengyue Su},
keywords = {Parasites, Hosts, Parasitic strategy, Symbiosis, Digital economy},
abstract = {Parasitism is a unique modus operandi of venture creation and development, particularly within the realm of the digital economy, where parasite firms make their living within or onto other firms or ecosystems and access their hosts’ resources uninvited. Based on the potential harm and benefits offered by the parasites, four types of parasites could be outlined that include commensal, reciprocal, siphoned, and abducted. Parasite firms need to attend to the three-stage implementation process of the parasitic strategy in terms of selection and engagement of a proper host, adaptation and penetration within the host, and renewal and transformation for ultimate self-fulfillment. This article offers a myriad of practical guidance for executives pursuing such a parasitic strategy as well as advices for executives in the corresponding hosts.}
}
@article{ZENG2025145262,
title = {Exploring outcome-driven policymaking on protected areas with an endogenous institutional model},
journal = {Journal of Cleaner Production},
volume = {501},
pages = {145262},
year = {2025},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2025.145262},
url = {https://www.sciencedirect.com/science/article/pii/S0959652625006122},
author = {Yongchao Zeng and Joanna Raymond and Calum Brown and Mark Rounsevell},
keywords = {Endogenous institutions, Protected areas (PAs), Land use system, Policy modelling, Agent-based modelling},
abstract = {Covering over 16 % of the global land surface, nearly 300,000 Protected Areas (PAs) play a pivotal role in conservation efforts worldwide. The allocation and management of these areas vary widely, reflecting the dynamism and complexity of the land use system. Understanding the impacts of PA-related policy mixes on ecosystem service outcomes and the wider land system is essential but challenging. In this research, we employ an endogenous institutional model coupled with an agent-based land use model to examine the processes and feedbacks from PA implementation and land system changes under multiple policies. We focus on modelled PA policy targets that aim to reach conservation outcomes by increasing a proxy for habitat diversity. Alongside other policies with different targets in the land system, PA policies generate dynamic patterns that are challenging to discern through an exogenous, non-systemic lens. Findings reveal that 1) Neither subsidies nor PAs in isolation effectively enhance habitat diversity in the model; however, their synergic implementation effectively increases it. 2) Increasing PA extent to 30 % of the land area does not harm modelled agricultural output in the long term, due to the land system's resilience and adaptability in providing ecosystem services. 3) When the geographic extent of PAs is predetermined, radical expansion proves more beneficial than gradual expansion, as the latter causes prolonged disruptions to existing land uses while accruing fewer cumulative sustainability benefits over time. These insights highlight the importance of a systemic, integrated approach to PA management for sustainable conservation outcomes.}
}
@article{PUSEY2024102888,
title = {Exploring the interaction among writing fluency, writing processes, and external resource access in second language writing assessment},
journal = {Computers and Composition},
volume = {74},
pages = {102888},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102888},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000641},
author = {Kerry Pusey and Yuko Goto Butler},
keywords = {Writing assessment, Writing processes, Writing fluency, English for academic purposes, Test task characteristics},
abstract = {As part of a larger investigation into the ecology of language tests, this study explores how writing fluency and writing processes are impacted by (dis)allowing access to external writing resources. An analysis was conducted of three international graduate students’ writing practices as they completed two argumentative writing assessment tasks. On one task, participants could access external writing resources (e.g., the internet) and had additional time to complete the task; on the other, access to writing resources was not permitted and a more restricted time limit was enforced. Data were collected from digital screen capture recordings of participants’ compositional practices and analyzed both qualitatively and quantitatively. Results indicated that participants took more time and wrote at a slower pace when they had access to external resources; however, additional time did not necessarily lead to a greater volume of writing. Participants also tended to shuttle between writing processes more frequently and execute more micro-level writing actions when they had access to external resources. However, there was substantial individual variation for both fluency and writing processes, highlighting the mediating role of individual differences in L2 writing. Implications for how the construct of academic writing ability is defined in different assessment contexts are discussed.}
}
@article{RENSHAW2024100154,
title = {Linking online activity to offline behavior: A meta-review of three decades of online-to-offline scholarship with future implications for AI},
journal = {Emerging Trends in Drugs, Addictions, and Health},
volume = {4},
pages = {100154},
year = {2024},
issn = {2667-1182},
doi = {https://doi.org/10.1016/j.etdah.2024.100154},
url = {https://www.sciencedirect.com/science/article/pii/S2667118224000138},
author = {Scott Leo Renshaw and Kathleen M. Carley},
keywords = {Network analysis, Social reinforcement, Meta-review, Online influences, Offline behavior},
abstract = {As society grapples with the emerging significance and implications of Large Language Models (LLMs), such as OpenAI’s ChatGPT, or Google’s Gemini, as well as other advancements in modern generative Artificial Intelligence (AI), it is crucial to recognize the existing role that data, algorithms, and online social networks have already played in shaping our contemporary society. This review article provides the first comprehensive examination of the current state of knowledge, across disciplinary divides, on how online influences impact offline behaviors, laying the necessary groundwork for investigating and researching the potential impact that these new technologies will have on our “offline” lives. Through a deep-dive collection of articles (n=149), we review and analyze research with measurable Online-to-Offline impacts (n=88). Within this Online-to-Offline criteria, we identify five emergent cross-cutting themes, namely: Social Diffusion, Social Reinforcement, Social Boundary & Identity Maintenance, Cognitive and Attitudinal Research, and Research on Vulnerable & Marginalized Impacts. Through a second wave snowball collection process, we construct a citation network from the broader Online and Offline research literature, allowing us to locate the Online-to-Offline subset as part of a larger intellectual discussion. Finally, we conduct a Term Frequency-Inverse Document Frequency (TF-IDF) analysis of terms used in the titles of these online/offline research papers, from 1990 to 2023, to identify the evolution of researchers’ conceptualization and framing of Online and Offline research across the past 30 years. The meta-review, presentation of high-level cross-cutting interdisciplinary themes, co-citation network analysis, and TF-IDF analysis collectively provide a cohesive and deeper understanding of the research space of online/offline influences. By taking stock of the ways in which online factors have already shaped individual, group, or organizational behaviors and social dynamics broadly in “offline” contexts, this work aims to provide a cohesive theoretical and empirical foundation for future researchers to better anticipate, address, and frame the future consequences of the rapidly evolving digitally influenced landscape we find ourselves in today.}
}
@article{KOSTOVCIK202566,
title = {Application possibilities of artificial intelligence in the field of transport and logistics},
journal = {Transportation Research Procedia},
volume = {87},
pages = {66-73},
year = {2025},
note = {VSI: TRPRO_LOGI 2024},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2025.04.109},
url = {https://www.sciencedirect.com/science/article/pii/S2352146525003564},
author = {Martin Kostovčík and Gabriel Fedorko and Nikoleta Mikušová and Vieroslav Molnár and Hana Neradilová and Martin Ďuriška},
keywords = {Artificial intelligence, logistics, transport, future},
abstract = {Artificial intelligence (AI) is a disruptive technology that is a part of several fields of society. The possibilities of artificial intelligence and its use are growing exponentially. From a technological point of view, it represents a challenge focused on its realization and implementation in a wide range of different areas of society to increase the quality of a set of processes and activities. The application possibilities of artificial intelligence implementation are also expanding in logistics and transport. It is primarily about using the potential of artificial intelligence in connection with the effectiveness and efficiency of the operation of logistics processes and logistics chains. The academic and scientific sphere’s task in logistics and transport is to examine in detail the use of artificial intelligence tools in this field, and further research is crucial for ongoing development.}
}
@article{WU2025103111,
title = {A survey on the current status of AI literacy lectures in China’s university libraries under the AIGC background},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {5},
pages = {103111},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103111},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325001077},
author = {Yubing Wu and Yifeng Lin and Yingying Liu and Yuer Yang},
keywords = {Top 40 QS ranking universities, “Double first-class” university, University library, GenAI, AI literacy},
abstract = {This paper selects the top 40 universities in the 2025 QS World University Rankings (including 41 tied universities) and 42 “Double First-Class” university libraries in China as research objects, and conducts an empirical study on their AI literacy lecture training activities (including lectures, seminars, etc.). By combining quantitative statistics (structured data such as activity name, sponsor, audience characteristics, and organizational form) with qualitative analysis (text mining of lecture training content), the current status of AI literacy lecture training in their university libraries is systematically examined. The study found that China’s “Double First-Class” university libraries have the following prominent problems in AI literacy lecture training: the degree of attention and implementation strength are different, the participation of librarians is low, lecture training mainly relies on teachers outside the library, the lecture training content is unbalanced, there is a lack of AI cognition and AI ethics, AI lecture training lacks systematicness, and AI skills education is out of touch with practical applications. Based on an international comparative perspective, the paper proposes eight optimization strategies: Strengthen the emphasis and implementation of AI literacy lecture training, provide continuous AI literacy lecture training for librarians and strengthen the construction of AI-Literate librarians, improve AI lecture training content and strengthen AI cognition and AI ethics education, establishing the AI workshop series: achieving systematic and comprehensive craining, increase AI practice components, holding geneAI research cafe, and cooperate with multiple institutions to organize AI lecture training, in order to provide practical reference for the innovative development of AI literacy education system in university libraries around the world.}
}
@article{SHAH2025,
title = {Yin-Yang of management theories: A preliminary textual analysis of four theories to map shifting economic and sociological influences in management literature during the new millennium},
journal = {European Management Journal},
year = {2025},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2025.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0263237325001021},
author = {Tushar R. Shah and Marwan A. Al-Shammari and Gajanan L. Ganji and D. Harold Doty},
abstract = {We introduce a novel text-analytic methodology for conducting systematic literature reviews in management research. By examining abstracts of articles published in leading management journals between 2000 and 2023, we assess the influence and interplay of four major theories: transaction cost economics (TCE) and agency theory (AT) from the economics domain and population ecology theory (PET) and institutional theory (IT) from the sociology domain. Our approach includes custom dictionary creation and probability scoring, allowing the quantification of theoretical inclinations in academic literature. Results indicate that IT, from the sociology field, was most influential from 2000 to 2018, whereas AT, from the economics field, gained prominence from 2018 onward. This dynamic interplay illustrates a competitive complementarity between economics and sociology, highlighting a shift in theoretical focus over time. Our study contributes to existing literature at two levels – conceptual and methodological. Conceptually, it provides insights into how economic and sociological paradigms have shaped management and strategy scholarship. Methodologically, it offers a custom-built quantitative method that facilitates the analysis of qualitative content across extensive literature bodies, validated through comparisons with established tools such as LIWC, VOSViewer, and BERT. While this study serves as a proof of concept with a focus on four theories, the methodology can be expanded to explore broader theoretical landscapes in management and related fields. Future research can build upon this framework by integrating additional theories and applying advanced machine learning tools to further advance the field of organizational studies.}
}
@article{BACIU2025105386,
title = {Neural networks through the lens of evolutionary dynamics},
journal = {BioSystems},
volume = {248},
pages = {105386},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105386},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002715},
author = {Dan C. Baciu},
keywords = {Evolutionary dynamics, Artificial neural networks, Artificial intelligence},
abstract = {This article revisits Artificial Neural Networks (NNs) through the lens of Evolutionary Dynamics. The two most important features of NNs are shown to reflect the two most general processes of Evolutionary Dynamics. This overlap may serve as a new and powerful connection between NNs and Evolutionary Dynamics, which encompasses a body of knowledge that has been built over multiple centuries and has been expanded to inspire applications across a vast range of disciplines. Consequently, NNs should also be applicable across the same range of disciplines—that is, much more broadly than initially envisioned. The article concludes by opening questions about NN dynamics, based on the new connection to Evolutionary Dynamics.}
}
@article{ZOU2025102606,
title = {Deep learning for cross-domain data fusion in urban computing: Taxonomy, advances, and outlook},
journal = {Information Fusion},
volume = {113},
pages = {102606},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102606},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524003841},
author = {Xingchen Zou and Yibo Yan and Xixuan Hao and Yuehong Hu and Haomin Wen and Erdong Liu and Junbo Zhang and Yong Li and Tianrui Li and Yu Zheng and Yuxuan Liang},
keywords = {Urban computing, Data fusion, Deep learning, Multi-modal data, Large language models, Sustainable development},
abstract = {As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.}
}
@article{LIANG2025114769,
title = {Quantitative evaluation of China’s energy storage policies: A ChatGPT-based PMC index modelling approach},
journal = {Energy Policy},
volume = {206},
pages = {114769},
year = {2025},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2025.114769},
url = {https://www.sciencedirect.com/science/article/pii/S0301421525002769},
author = {Jing Liang and Yuqi Wang and Wei Li and Weihan Wang},
keywords = {Energy storage system, Policy evaluation, Policy modelling consistency, ChatGPT-based},
abstract = {Efficient energy grid systems can improve operational efficiency and reduce carbon emissions by integrating diverse renewable energy generation sources. As a distinct asset class within the electric grid, energy storage necessitates well-defined regulatory and financial policies to support its development and large-scale deployment. This makes it essential to establish an effective and consistent policy evaluation framework to support the growth of the energy storage industry. In this study, we propose a ChatGPT-based Policy Model Consistency framework to evaluate 203 energy supply policies issued by China’s central and local governments during the “14th Five-Year Plan” period (2021–2024). The results demonstrate the effectiveness of AI-powered policy analysis in building quantitative and objective policy evaluation systems. In addition, the findings highlight the ability of the system to provide a comprehensive analysis and practical recommendations for the development of energy storage systems in China.}
}
@article{GUAN2024100323,
title = {AI in informal digital English learning: A meta-analysis of its effectiveness on proficiency, motivation, and self-regulation},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100323},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100323},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001267},
author = {Lihang Guan and Shaofeng Li and Mingyue Michelle Gu},
keywords = {Generative artificial intelligence, Informal digital learning of English, English proficiency, Learning motivation, Self-regulation},
abstract = {This meta-analysis examines the efficacy of generative artificial intelligence (GenAI) in second language acquisition within self-directed, out-of-classroom informal contexts. A total of 15 studies meeting the inclusion criteria were identified that examined the impact of GenAI on second-language proficiency, motivation, and self-regulation. GenAI was shown to have significant effects on English proficiency and self-regulation, demonstrating its versatility in enhancing language learning outcomes. However, GenAI failed to show significant effects on learning motivation, and based on this finding we highlight the need to develop measures of motivation that are suitable for GenAI in education. Possible ways to apply GenAI in the informal language learning environment are also discussed based on the included literature.}
}
@article{GASCOYNE2025103382,
title = {First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network},
journal = {Ecological Informatics},
pages = {103382},
year = {2025},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2025.103382},
url = {https://www.sciencedirect.com/science/article/pii/S1574954125003917},
author = {Andrew Gascoyne and Wendy Lomas},
keywords = {Bioacoustics, Artificial intelligence, Machine learning, Hopfield neural networks, Signal processing},
abstract = {A growing issue within conservation bioacoustics is the laborious task of analysing the vast amount of data generated from the use of passive acoustic monitoring devices. In this paper, we present an alternative AI model which has the potential to help alleviate this problem. Our model formulation addresses the key issues encountered when using current AI models for bioacoustic analysis, namely: the limited training data available; the environmental impact, particularly in energy consumption and carbon footprint of training and implementing these models; and the associated hardware requirements. The model developed in this work uses associative memory via a transparent and explainable Hopfield neural network to store signals and detect similar signals which can then be used to classify species. Training is rapid (3milliseconds), as only one representative signal is required for each target sound within a dataset. The model is fast, taking only 5.4seconds to pre-process and classify all 10384 publicly available bat recordings, on a standard Apple MacBook Air. The model is also lightweight, i.e., has a small memory footprint of 144.09MB of RAM usage. Hence, the low computational demands make the model ideal for use on a variety of standard personal devices with potential for deployment in the field via edge-processing devices. It is also competitively accurate, with up to 86% precision on the labelled dataset used to evaluate the model. In fact, we could not find a single case of disagreement between model and manual identification via expert field guides. Although a dataset of bat echolocation calls was chosen to demonstrate this first-of-its-kind AI model, trained on only two representative echolocation calls, the model is not species specific. In conclusion, we propose an equitable AI model that has the potential to be a game changer for fast, lightweight, sustainable, transparent, explainable and accurate bioacoustic analysis.}
}
@article{DUBBERLY2023135,
title = {How Might We Help Designers Understand Systems?},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {9},
number = {2},
pages = {135-156},
year = {2023},
note = {The Future of Design Education: Rethinking Design Education for the 21st Century},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2023.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S2405872623000357},
author = {Hugh Dubberly and Paul Pangaro},
keywords = {Complex adaptive systems, Designing for systems, Models, Product-service ecologies, User agency, Ethics},
abstract = {The Future of Design Education working group on systems outlines the growth of professional practice from a focus on designing artifacts to also include designing systems and designing in the context of systems. They describe a holistic approach to design, one grounded in systems theory and recognition that systems intersect with all aspects of design. They acknowledge that systems are social constructions and can be framed in many ways. They assert that systems exhibit structural and behavioral patterns across instances, and they advocate for the development of models (proxies) that forefront these patterns and make it possible to align views of situations and possible future ways of being with teams and stakeholders under participatory design processes. The working group also notes that systems are never complete and that even small changes may have large effects. This article lists a series of recommendations aimed at design students regarding the knowledge that they should have and the actions that they should take when working around systems, and it provides an overview through which to consider more specific recommendations related to natural, social, and technical systems by other Future of Design Education working groups.}
}
@article{JING20251096,
title = {A Review of Research on Intelligent Modeling Approaches for Rural Wastewater Quality Prediction},
journal = {Procedia Computer Science},
volume = {266},
pages = {1096-1101},
year = {2025},
note = {The 12th International Conference on Information Technology and Quantitative Management (ITQM 2025)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.08.135},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925024470},
author = {Jiaqi Jing and Pei Quan},
keywords = {rural wastewater management, water quality prediction, smart governance, data fusion, soft measurement},
abstract = {Water scarcity has become a major global concern, and the utilization of wastewater resources is seen as a key solution to address the supply-demand imbalance. Compared to urban areas, rural wastewater treatment lags significantly behind due to underdeveloped infrastructure and complex water quality, posing a major constraint to the development of wastewater resource utilization. Mechanism-driven models struggle with the non-stationary data in rural wastewater, while data-driven models are becoming increasingly popular due to their ability to simulate non-linear relationships and adapt to changing conditions, making them an effective way to solve the existing challenges. This paper reviews the development of data-driven models for water quality prediction, analyzing the performance and application scenarios of three types of methods: traditional statistical models, machine learning models, and deep learning models. Additionally, through an in-depth discussion of these methods and an analysis of the specific challenges in rural wastewater management, we propose optimization directions for rural wastewater modeling, including multi-source data fusion, soft measurement methods, and the integration of data and mechanisms, to support the development of intelligent and efficient prediction systems.}
}
@article{SMITH20241,
title = {Guest editorial: Artificial intelligence and composing just education futures},
journal = {English Teaching: Practice & Critique},
volume = {23},
number = {1},
pages = {1-5},
year = {2024},
issn = {1175-8708},
doi = {https://doi.org/10.1108/ETPC-04-2024-202},
url = {https://www.sciencedirect.com/science/article/pii/S1175870824000116},
author = {Anna Smith and Jennifer Higgs and José Ramón Lizárraga and Vaughn W.M. Watson}
}
@article{ELSAER2025103200,
title = {SeagrassFinder: Deep learning for eelgrass detection and coverage estimation in the wild},
journal = {Ecological Informatics},
volume = {90},
pages = {103200},
year = {2025},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2025.103200},
url = {https://www.sciencedirect.com/science/article/pii/S1574954125002092},
author = {Jannik Elsäßer and Laura Weihl and Veronika Cheplygina and Lisbeth Tangaa Nielsen},
keywords = {Ecological monitoring, Marine biology, Marine ecology, Marine imaging, Deep learning, Computer vision, Transfer learning},
abstract = {Seagrass meadows play a crucial role in marine ecosystems, providing benefits such as carbon sequestration, water quality improvement, and habitat provision. Monitoring the distribution and abundance of seagrass is essential for environmental impact assessments and conservation efforts. However, the current manual methods of analyzing underwater video data to assess seagrass coverage are time-consuming and subjective. This work explores the use of deep learning models to automate the process of seagrass detection and coverage estimation from underwater video data. We create a new dataset of over 8,300 annotated underwater images, and subsequently evaluate several deep learning architectures, including ResNet, InceptionNetV3, DenseNet, and Vision Transformer for the task of binary classification on the presence and absence of seagrass by transfer learning. The results demonstrate that deep learning models, particularly Vision Transformers, can achieve high performance in predicting eelgrass presence, with AUROC scores exceeding 0.95 on the final test dataset. The application of underwater image enhancement further improved the models’ prediction capabilities. Furthermore, we introduce a novel approach for estimating seagrass coverage from video data, showing promising preliminary results that align with expert manual labels, and indicating potential for consistent and scalable monitoring. The proposed methodology allows for the efficient processing of large volumes of video data, enabling the acquisition of much more detailed information on seagrass distributions in comparison to current manual methods. This information is crucial for environmental impact assessments and monitoring programs, as seagrasses are important indicators of coastal ecosystem health. This project demonstrates the value that deep learning can bring to the field of marine ecology and environmental monitoring.}
}
@article{GHIMIRE2025102913,
title = {Utilizing ChatGPT to integrate world English and diverse knowledge: A transnational perspective in critical artificial intelligence (AI) literacy},
journal = {Computers and Composition},
volume = {75},
pages = {102913},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102913},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000896},
author = {Asmita Ghimire},
abstract = {This article proposes the implementation of a transnational post-digital pedagogy and Critical AI literacy incorporating ChatGPT in the classroom. It draws upon Scott Graham's suggestion for a multidimensional recursive writing process, emphasizing fact-checking and revision while utilizing ChatGPT. Additionally, it incorporates Suresh Canagarajah's (2019) theorization of transnational habits of writing among most international, multilingual, and marginalized students, which, according to him, are characterized by rhetorical sensitivity, depth of awareness, and linguistic knowledge. Based on these empirical and theoretical perspectives, this article proposes pausing, pondering, posing, and prioritizing as critical praxis that can be built into metacognitive activities. To explain this praxis, it showcases two kinds of metacognitive activities for fostering transnational habits among students through fact-checking processes. Similarly, it suggests designing the revision phase of writing assignments to allow students to incorporate their English language skills into the classroom. This paper identifies engaging in critical dialogue with ChatGPT and encouraging self-reflection on fact-checking and revision as effective ways to cultivate a transnational habitus among students. It concludes that adopting a transnational post-digital critical pedagogy and critical AI literacy in the writing process benefits both national and international students by promoting diverse linguistic norms and perspectives.}
}
@article{MOHAMEDSABRI2025100066,
title = {Comparative machine learning analysis for gold mineral prediction using random forest and XGBoost: A data-driven study of the Greater Bendigo Region, Victoria},
journal = {Geomatica},
volume = {77},
number = {2},
pages = {100066},
year = {2025},
issn = {1195-1036},
doi = {https://doi.org/10.1016/j.geomat.2025.100066},
url = {https://www.sciencedirect.com/science/article/pii/S1195103625000229},
author = {Azirahtul Atifah {Mohamed Sabri} and Sarath Tomy and Choiru Za’in},
keywords = {Machine learning, Random Forest, XGBoost, Gold mineralisation, Bendigo, Geophysical data, Mineral exploration},
abstract = {Gold mineral exploration remains critical to supporting global industries, yet traditional methods relying on manual interpretation of geophysical data are increasingly inefficient and prone to error, particularly when targeting undercover deposits. In Australia, most exploration research has focused on Western Australia, while the Greater Bendigo region in Victoria remains underexplored using modern data-driven approaches, despite its rich mining history and availability of high-resolution geophysical datasets. This study aims to demonstrate that a geospatial analysis methodology based on a machine learning approach enables high-accuracy prediction of gold mineral deposits in Bendigo. The methodology integrates geophysical data, including gravity, total magnetic intensity, and radiometric surveys, combined with geospatial preprocessing, scalable multi-resolution modelling, spatial labelling, and ensemble machine learning techniques, using Random Forest as the primary algorithm and XGBoost as a comparative model. Model performance was assessed using accuracy scores, ROC-AUC metrics, and spatial validation methods, including checkerboard and cluster-based cross-validation, across different spatial scales. Results showed that gravity and magnetic features were the strongest predictors, while radiometric features provided supporting information. Coarser spatial resolutions produced more stable predictions, reflecting regional geological patterns. The study presents a reproducible and adaptable machine learning methodology that addresses key exploration challenges and advances mineral prospectivity analysis using open-access geophysical data.}
}
@article{HAZARD2025109780,
title = {Beneath the surface: Unsolved questions in soil virus ecology},
journal = {Soil Biology and Biochemistry},
volume = {205},
pages = {109780},
year = {2025},
issn = {0038-0717},
doi = {https://doi.org/10.1016/j.soilbio.2025.109780},
url = {https://www.sciencedirect.com/science/article/pii/S0038071725000732},
author = {Christina Hazard and Karthik Anantharaman and Luke S. Hillary and Uri Neri and Simon Roux and Gareth Trubl and Kurt Williamson and Jennifer Pett-Ridge and Graeme W. Nicol and Joanne B. Emerson},
keywords = {Soil viruses, RNA viruses, Viral ecology, Metagenomics, Viromics, Biogeochemical cycling},
abstract = {Soil virus ecology is an exciting but still nascent field of research in soil microbiology. While there has been a recent surge in soil virus research studies, many fundamental questions remain unanswered, and a range of technical and bioinformatic challenges need to be overcome. In this perspective article, we present a series of key questions that highlight fruitful research areas for ongoing and future efforts. These include describing the challenges involved in understanding soil viral abundance and activity, spatiotemporal dynamics, life strategy prevalence, virus-mediated biogeochemical impacts, viral protein function, host prediction, and soil RNA virus discovery. In the near term, combining approaches (e.g., cultivation-based, meta-omics, biogeochemical, experimental, and bioinformatic) will be key to assessing the ecological and biogeochemical impacts of soil viruses from the microscopic to the field and global scales. Still, we stress that results must be tempered by current methodological limitations and highlight knowledge gaps that are most pressing to fill via new methods or measurements, such as the prevalence of different viral replication strategies across soils, the fate of microbial necromass carbon after viral lysis, the frequency of virus-host encounters that do not lead to successful infections yet could be bioinformatically mistaken as infections, and the diversity and ecological impacts of RNA viruses in soil.}
}
@article{GAO2025103141,
title = {A study on international scientific journal cover design driven by generative artificial intelligence},
journal = {Displays},
volume = {90},
pages = {103141},
year = {2025},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2025.103141},
url = {https://www.sciencedirect.com/science/article/pii/S0141938225001787},
author = {Zhan Gao and Zhenyu Li},
keywords = {Scientific journal cover design, Artificial intelligence, Midjourney, Stable diffusion, Deepseek, VIKOR},
abstract = {The application of generative artificial intelligence technology in the field of visual design is increasingly widespread, particularly showing significant potential in scientific publications. In order to overcome the limitations of traditional journal cover design and enhance the artistic quality and communicative effectiveness of journal covers, this study proposes a method for designing international scientific journal covers driven by artificial intelligence. The method integrates numerous generative artificial intelligence technologies and multi-criteria decision-making methods, applying them to the design practice of food science journals, thereby improving the efficiency of journal cover design and publication. The integrated method first uses the coding method of grounded theory to extract five design dimensions critical to journal cover design and constructs a triple-mapping relationship model of technological translatability, visual expressiveness, and alignment with public cognition and cultural background, providing a research foundation for organizing design elements to align with the journal’s positioning. The DeepSeek large language model is employed to generate creative keywords for the journal cover, which are then translated into descriptive instructions recognizable by Midjourney. Subsequently, Midjourney is used to generate preliminary cover sketches to quickly visualise the creative concept, and the controlnet function of Stable Diffusion is employed to control the outline of the sketch’s line art, followed by experimentation and optimisation across dimensions such as visual style and tonal range. Finally, the VIKOR method is applied to evaluate and rank the six generated cover design proposals. The evaluation criteria encompass scientific content expression, visual aesthetics, and communication and acceptance, across three dimensions with fifteen indicators. The selected design proposals are then subjected to collaborative optimisation between human input and artificial intelligence. The integrated method offers a systematic and innovative framework, enhancing the efficiency, creativity, and visual impact of journal cover design, and provides both theoretical and practical references for future academic publishing.}
}
@article{HU2025100735,
title = {Design and evaluation of a GenAI-based personalized educational content system tailored to personality traits and emotional responses for adaptive learning},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100735},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100735},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001502},
author = {Wentao Hu and Zichen Shao},
keywords = {Adaptive learning, GenAI, Personality traits, Emotional response, Design-based research},
abstract = {This research integrates personality traits and emotional responses with GenAI to create personalized educational content. Using a design-based approach, the Psychologically-Aware Generative Education (PAGE) system was developed to adapt learning materials based on learners' Big Five personality profiles and real-time emotional feedback. Quasi-experimental testing with 200 university students demonstrated that PAGE significantly enhanced emotional satisfaction (4.4/5 vs 3.6/5, Cohen's d = 1.05) and learning engagement compared to traditional adaptive systems, with 22 % higher task completion rates (87.6 % vs 72.3 %) and 34 % increased study duration. The system successfully tailored content style, difficulty, and support mechanisms according to individual psychological characteristics. Content personalization was particularly effective for students with high neuroticism, reducing dropout rates by 48 % and negative emotions. This study provides empirical evidence that psychological adaptation in educational technology produces more engaging learning experiences than solely cognitive-based approaches, contributing design principles for developing psychologically-aware AI systems in education. These findings offer practical implications for educational institutions seeking to implement more humanized and culturally responsive technological solutions.}
}
@article{XIANG2025105222,
title = {Examining the dynamics of knowledge convergence in online learning context: A network perspective},
journal = {Computers & Education},
volume = {227},
pages = {105222},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105222},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524002367},
author = {Mengtong Xiang and Jingjing Zhang and Yue Li},
keywords = {Knowledge convergence, Online learning, Collaborative learning, Network analysis},
abstract = {Knowledge convergence, originating from computer-supported collaborative learning (CSCL), is often defined as building a shared cognitive understanding through social interactions. With an increasing focus on large-scale collaboration and online learning in CSCL, it is crucial to examine how knowledge convergence occurs in online settings. This study investigates how learners develop cognitive consensus in online discussions and assess how social interactions and learners' role influence these dynamics in a MOOC using video-based social annotation. Mixed-methods, including Epistemic Network Analysis (ENA), Simulation Investigation for Empirical Network Analysis (SIENA), and role trajectory clustering were employed. The findings suggest that cognitive consensus in discussions originates from sharing similar experiences and evolves into more advanced levels over time. Reciprocity and transitivity are crucial for establishing network cohesion while achieving cognitive consensus. Learners with similar role trajectories tend to interact together. This study expands the traditional CSCL paradigm by examining how social interactions shape discussion network dynamics and how learners’ role trajectories influence these dynamics. We argue that network cohesiveness should be included in the framework of online knowledge convergence, alongside cognitive consensus. Dynamic network analysis is essential for understanding the complex mechanisms driving online knowledge convergence occurring, where the cognitive and social attributes of learning are interwoven.}
}
@article{ZHANG2025104090,
title = {Expert-level policy style measurement via knowledge distillation with large language model collaboration},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104090},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104090},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325000329},
author = {Yujie Zhang and Biao Huang and Weikang Yuan and Zhuoren Jiang and Longsheng Peng and Shuai Chen and Jie-Sheng Tan-Soo},
keywords = {Policy style, Knowledge distillation, LLM collaboration},
abstract = {Policy style is a crucial concept in policy science that reflects persistent patterns in the policy process across different governance settings. Despite its importance, policy style measurement faces issues of complexity, subjectivity, data sparseness, and computational cost. To overcome these obstacles, we propose KOALA, a novel KnOwledge distillation framework based on large lAnguage modeL collAboration. It transforms the weak scoring abilities of LLMs into a pairwise ranking problem, employs a small set of expert-annotated samples for non-parametric learning, and utilizes knowledge distillation to transfer insights from LLMs to a smaller, more efficient model. The framework incorporates multiple LLM-based agents (Prompter, Ranker, and Analyst) collaborating to comprehend complex measurement standards and self-explain policy style definitions. We validate KOALA on 4,572 Chinese government work reports (1954–2019) from central, provincial, and municipal levels, with a focus on the imposition dimension of policy style. Extensive experiments demonstrate KOALA’s effectiveness in measuring the intensity of policy style, highlighting its superiority over state-of-the-art methods. While GPT-4 achieves only 66% accuracy in pairwise ranking of policy styles, KOALA, despite being based on GPT-3.5, achieves a remarkable 85% accuracy, highlighting significant performance improvement. This framework offers a transferable approach for quantifying complex social science concepts in textual data, bridging computational techniques with social science research.}
}
@article{QIU2025109341,
title = {Using artificial intelligence tools for data quality evaluation in the context of microplastic human health risk assessments},
journal = {Environment International},
volume = {197},
pages = {109341},
year = {2025},
issn = {0160-4120},
doi = {https://doi.org/10.1016/j.envint.2025.109341},
url = {https://www.sciencedirect.com/science/article/pii/S0160412025000923},
author = {Yanning Qiu and Svenja Mintenig and Margherita Barchiesi and Albert A. Koelmans},
keywords = {Large language models, ChatGPT, Gemini, Quality Assurance and Quality Control},
abstract = {Concerns about the negative impacts of microplastics on human health are increasing in society, while exposure and risk assessments require high-quality, reliable data. Although quality assurance and –control (QA/QC) frameworks exist to evaluate the reliability of data for these purposes, manually assessing studies is too time-consuming and prone to inconsistencies due to semantic ambiguities and evaluator bias. The rapid growth of microplastic studies makes manually screening relevant data practically unfeasible. This study explores the potential of artificial intelligence (AI), specifically large language models (LLMs) such as OpenAI’s ChatGPT and Google’s Gemini, to streamline and standardize the QA/QC screening of data in microplastics research. We developed specific prompts based on previously published QA/QC criteria for the analysis of microplastics in drinking water and its sources, and used these to instruct AI tools to evaluate 73 studies published between 2011 and 2024. Our approach demonstrated the effectiveness of AI in extracting relevant information, interpreting the reliability of studies, and replicating human assessments. The findings indicate that AI-assisted assessments show promise in improving speed, consistency and applicability in QA/QC tasks, as well as in ranking studies or datasets based on their suitability for exposure and risk assessments. This groundbreaking application of LLMs in the environmental sciences suggests that AI can play a vital role in harmonizing microplastics risk assessments within regulatory frameworks and demonstrates how to meet the demands of an increasingly data-intensive application domain.}
}
@article{ZHAO2025145607,
title = {A novel machine learning-based method for identifying Industrial Symbiosis opportunities},
journal = {Journal of Cleaner Production},
volume = {513},
pages = {145607},
year = {2025},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2025.145607},
url = {https://www.sciencedirect.com/science/article/pii/S0959652625009576},
author = {Lan Zhao and Yajuan Sun and Gaoxi Xiao},
keywords = {Industrial Symbiosis opportunity identification, Machine learning, Neural networks},
abstract = {Industrial Symbiosis (IS) is a sub-field of Industrial Ecology (IE) that aims to reuse waste streams as resources among industries to achieve higher resource efficiency. A common method for identifying IS opportunities is input–output matching, which links the output (waste) of one company to the input of another. In such a process, obtaining data on resource and waste streams of participating companies becomes a prerequisite. However, data acquisition is challenging due to issues like data confidentiality and the demand of extensive manual input. It is known that process information is generally kept confidential, resulting in lack of data on types of wastes and resources available in the system. Moreover, collecting such data, typically via industrial workshops, is time-consuming and costly. To address the problem, we propose to take a predictive approach to obtain the input and output streams of companies using advanced Machine Learning (ML) techniques, eliminating the need for companies to register their process data prior to IS implementation. Specifically, we develop a novel Neural Network (NN) model to predict whether a waste is an input or output of an activity based on the textual descriptions of the waste and the activity. The developed models achieve an F1-score higher than 0.82 on the test set. We further validate the model on an external unseen dataset and demonstrate its application in identifying IS opportunities through a case study. By predicting the input and output data, the proposed method enables input–output matching without extensive information sharing by companies, serving as a preliminary step for identifying IS opportunities automatically.}
}
@article{WANG2025112189,
title = {Improving knowledge management in building engineering with hybrid retrieval-augmented generation framework},
journal = {Journal of Building Engineering},
volume = {103},
pages = {112189},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.112189},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225004255},
author = {Zhiqi Wang and Zhongcun Liu and Weizhen Lu and Lu Jia},
keywords = {Retrieval augmented generation, Large language model, Knowledge engineering, Risk and error recognition, Reasoning},
abstract = {Domain knowledge is a critical asset that provides the foundation for a range of building activities, including but not limited to design, construction, operation, and maintenance. However, existing approaches to knowledge engineering often require extensive up-front work and are limited in generalizability. In recent years, large language models (LLMs) have undergone significant growth and demonstrated notable generalization and reasoning capabilities. Nevertheless, the deployment of LLMs in the field of buildings has been constrained by several factors, including hallucinations, a lack of domain-specific knowledge, difficulties in updating knowledge, and data security concerns. This study aims to develop an improved retrieval augmented generation (RAG) framework based on domain characteristics for general, intelligent, and scalable AI-based applications. The primary advancement is the proposal of a hybrid index based on vectors, a property graph, and keywords, accompanied by a corresponding hybrid retrieval strategy. To evaluate the proposed framework comprehensively, three tasks were designed and executed: basic queries, risk and error recognition in complex queries, and open text generation. The results show that the improved RAG significantly outperforms the baseline and the native LLM in all three tasks. This study advances the integration of domain knowledge with generative AI and demonstrates the potential of LLM-RAG-based solutions for application in building lifecycle management.}
}
@article{XU2025348,
title = {Design of Question-Answering and Reasoning System Combining Large Language Models and Knowledge Graphs},
journal = {Procedia Computer Science},
volume = {262},
pages = {348-357},
year = {2025},
note = {The 5th International Conference on Multi-modal Information Analytics (MMIA)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.05.062},
url = {https://www.sciencedirect.com/science/article/pii/S187705092501909X},
author = {Yanru Xu},
keywords = {LLM, LLaMa, KG, question-answering, reasoning, system design, command fine-tuning},
abstract = {Problem reasoning uses natural language processing technology to analyze natural language questions input by users, and finally generate accurate and suitable answers. At present, the performance of Q&A model has been significantly improved, and the deep semantic understanding of text can be obtained through accurate knowledge reasoning. Based on LLaMa model, this paper systematically studies Transformer architecture, normalization technology, rotary position coding and packet query attention, creatively studies the combination of LLM and KG, and constructs a mathematical model of instruction fine-tuning algorithm. It not only understands the surface meaning of text, but also uses background knowledge such as entity relationships in KG to execute instructions more accurately and intelligently. The LLM studied in this paper is combined with KG to build a question-and-answer reasoning system, which can overcome the "illusion" problem of large models. KG significantly improves the accuracy by constrains the generated results of large models with structured knowledge.}
}
@article{ZHUANG2025103332,
title = {Large language models for automated scholarly paper review: A survey},
journal = {Information Fusion},
volume = {124},
pages = {103332},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103332},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525004051},
author = {Zhenzhen Zhuang and Jiandong Chen and Hongfeng Xu and Yuwen Jiang and Jialiang Lin},
keywords = {Automated scholarly paper review, Large language models, Peer review, Academic publishing, Artificial intelligence},
abstract = {Large language models (LLMs) have significantly impacted human society, influencing various domains. Among them, academia is not simply a domain affected by LLMs, but it is also the pivotal force in the development of LLMs. In academic publication, this phenomenon is represented during the incorporation of LLMs into the peer review mechanism for reviewing manuscripts. LLMs hold transformative potential for the full-scale implementation of automated scholarly paper review (ASPR), but they also pose new issues and challenges that need to be addressed. In this survey paper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin with a survey to find out which LLMs are used to conduct ASPR. Then, we review what ASPR-related technological bottlenecks have been solved with the incorporation of LLM technology. After that, we move on to explore new methods, new datasets, new source code, and new online systems that come with LLMs for ASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and investigate the attitudes and reactions of publishers and academia to ASPR. Lastly, we discuss the challenges and future directions associated with the development of LLMs for ASPR. This survey serves as an inspirational reference for the researchers and can promote the progress of ASPR for its actual implementation.}
}
@article{ZHU2023112,
title = {Unveiling the nexus and promoting integration of diverse factors: Prospects of big data-driven artificial intelligence technology in achieving carbon neutrality in Chongming District},
journal = {Water-Energy Nexus},
volume = {6},
pages = {112-121},
year = {2023},
issn = {2588-9125},
doi = {https://doi.org/10.1016/j.wen.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S2588912523000164},
author = {Wenbo Zhu and Renzhou Gui and Ru Guo},
keywords = {New generation of information technology, Big data, Artificial intelligence, Deep learning, Multi-element nexus},
abstract = {Climate change is one of the most pressing challenges facing the world today. The large amount of greenhouse gas emissions produced by human activities, especially the emission of carbon dioxide, is an important driving factor behind climate issues. Under the background of China’s “3060” decarbonization goal”, Chongming District in Shanghai is actively promoting the construction of a world-class ecological island and is committed to creating a carbon–neutral demonstration zone with global influence. However, Chongming District faces challenges as the mechanism of carbon-neutrality transition path remains unclear. The data related to evaluating carbon neutrality status are heterogeneous from multiple sources. It is difficult to effectively implement relevant evaluation and response measures, impeding the progress of its low-carbon transformation. In response to the aforementioned challenges, this paper will propose and discuss the potential methods based on the new generation of information technology, represented by big data and artificial intelligence. These technologies aim to facilitate the integration of diverse factors, including carbon, and explore the nexus among them, thus exploring pathways for low-carbon transformation, and ultimately achieving decarbonization goal in Chongming District. Hopefully, the research conducted in this paper will contribute to the efforts of China and the global community in addressing carbon-related challenges and advancing towards a more sustainable and low-carbon future.}
}
@article{GORIDKOV2024964,
title = {What's in this LCA Report? A Case Study on Harnessing Large Language Models to Support Designers in Understanding Life Cycle Reports},
journal = {Procedia CIRP},
volume = {122},
pages = {964-969},
year = {2024},
note = {31st CIRP Conference on Life Cycle Engineering},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.01.131},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124001756},
author = {Nicole Goridkov and Ye Wang and Kosa Goucher-Lambert},
keywords = {sustainable design, life cycle reports, document understanding, knowledge management, large language models},
abstract = {Life cycle assessment (LCA) is a well-established approach and benchmark for design for sustainability efforts, in which detailed reports are produced that can serve as decision-making guides for developing new products. However, LCA reports are typically dense and technically complex, making it difficult for many engineering design project stakeholders to appropriately leverage the information found within them. Our work seeks to understand and improve the transfer of knowledge from LCA reports during the early stages of the design process, specifically leveraging the natural language capabilities of large language models (LLMs). In this paper, we investigate how four LCA-and sustainability-centric prompting frameworks can extract relevant design knowledge from LCA reports, demonstrated through a case study where an LLM (ChatGPT) is prompted on a provided electric toothbrush LCA report. Key findings illustrate the prompting frameworks can establish high-level summaries and identify life-cycle specific information, but the development of specific and design-focused sub-prompts will allow for richer understanding. We envision designers can use these proposed frameworks to query an LLM to gain context and insights from relevant LCA reports. The proposed techniques serve as a basis for automatic knowledge extraction from life cycle documents, creating accessible information in a user-friendly manner for designers who look to develop life-cycle-informed products.}
}
@article{XU2025146280,
title = {Certainty in uncertainty: Assessing the impact of climate policy uncertainty on the green transformation of manufacturing firms in China},
journal = {Journal of Cleaner Production},
volume = {522},
pages = {146280},
year = {2025},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2025.146280},
url = {https://www.sciencedirect.com/science/article/pii/S0959652625016300},
author = {Lei Xu and Xuanyu Du and Qiuyu Tang},
keywords = {Climate policy uncertainty, Green transformation, Growth option theory, Media attention and sentiment},
abstract = {Global climate governance has led to frequent climate policy revisions, resulting in Climate Policy Uncertainty (CPU). Despite this, policies generally follow a long-term trend of tightening. In this context, Green Transformation (GT) has become a strategic tool for firms to mitigate risks and secure competitive advantages. Using machine learning techniques to measure corporate GT and media sentiment, this study analyzes data from Chinese A-share listed companies between 2008 and 2022. Drawing on growth options theory, we empirically examine the impact of CPU on the GT of manufacturing firms. Results show that increased CPU significantly accelerates the GT process. This effect is mainly driven by enhanced green innovation and upgraded green governance. Additionally, media coverage of environmental issues and shifts in sentiment strengthen external governance mechanisms. Specifically, both positive and negative environmental news coverage significantly enhance the positive impact of CPU on corporate GT, while positive shifts in sentiment produce the opposite effect. Heterogeneity analysis reveals that CPU's impact is more pronounced in small private firms, heavily polluting industries, firms with lower executive environmental awareness, and those with higher perceived uncertainty. This study provides a comprehensive framework for understanding the dynamic relationship between CPU and GT, offering insights for policymakers aiming to balance climate policy with corporate green strategies.}
}
@article{TAN2025113706,
title = {ForestryBERT: A pre-trained language model with continual learning adapted to changing forestry text},
journal = {Knowledge-Based Systems},
volume = {320},
pages = {113706},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113706},
url = {https://www.sciencedirect.com/science/article/pii/S095070512500752X},
author = {Jingwei Tan and Huaiqing Zhang and Jie Yang and Yang Liu and Dongping Zheng and Xiqin Liu},
keywords = {Pre-trained language model, Domain-specific pre-training, Continual learning, Forestry text processing, Text classification, Extractive question answering, Natural language processing},
abstract = {Efficient utilization and enhancement of the growing volume of forestry-related textual data is crucial for advancing smart forestry. Pre-trained language models (PLMs) have demonstrated strong capabilities in processing large unlabeled text. To adapt a general PLM to a specific domain, existing studies typically employ a single target corpus for one-time pre-training to incorporate domain-specific knowledge. However, this approach fails to align with the dynamic processes of continuous adaptation and knowledge accumulation that are essential in real-world scenarios. Here, this study proposes ForestryBERT, a BERT model that is continually pre-trained on three Chinese forestry corpora comprising 204,636 texts (19.66 million words) using a continual learning method called DAS.11DAS is referred to as Continual Domain-Adaptive Pre-training of PLMs with Soft-masking We evaluate the model on both text classification and extractive question answering tasks using five datasets for each task. Experimental results show that ForestryBERT outperforms five general-domain PLMs and further pre-trained PLMs (without DAS) across eight custom-built forestry datasets. Moreover, PLMs using DAS exhibit a forgetting rate of 0.65, which is 1.41 lower than PLMs without DAS, and demonstrate superior performance on both new and old tasks. These findings indicate that ForestryBERT, based on continual learning, effectively mitigates catastrophic forgetting and facilitates the continuous acquisition of new knowledge. It expands its forestry knowledge by continually absorbing new unlabeled forestry corpora, showcasing its potential for sustainability and scalability. Our study provides a strategy for handling the growing volume of forestry text during PLM construction, a strategy that is also applicable to other domains.}
}
@article{ZHANG2025100608,
title = {Fine-tuning large language models for interdisciplinary environmental challenges},
journal = {Environmental Science and Ecotechnology},
volume = {27},
pages = {100608},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2025.100608},
url = {https://www.sciencedirect.com/science/article/pii/S2666498425000869},
author = {Yuanxin Zhang and Sijie Lin and Yaxin Xiong and Nan Li and Lijin Zhong and Longzhen Ding and Qing Hu},
keywords = {Environmental science, Artificial intelligence, Large language model, Fine-tuning, Instruction dataset},
abstract = {Large language models (LLMs) are revolutionizing specialized fields by enabling advanced reasoning and data synthesis. Environmental science, however, poses unique hurdles due to its interdisciplinary scope, specialized jargon, and heterogeneous data from climate dynamics to ecosystem management. Despite progress in subdomains like hydrology and climate modeling, no integrated framework exists to generate high-quality, domain-specific training data or evaluate LLM performance across the discipline. Here we introduce a unified pipeline to address this gap. It comprises EnvInstruct, a multi-agent system for prompt generation; ChatEnv, a balanced 100-million-token instruction dataset spanning five core themes (climate change, ecosystems, water resources, soil management, and renewable energy); and EnvBench, a 4998-item benchmark assessing analysis, reasoning, calculation, and description tasks. Applying this pipeline, we fine-tune an 8-billion-parameter model, EnvGPT, which achieves 92.06 ± 1.85 % accuracy on the independent EnviroExam benchmark—surpassing the parameter-matched LLaMA-3.1–8B baseline by ∼8 percentage points and rivaling the closed-source GPT-4o-mini and the 9-fold larger Qwen2.5–72B. On EnvBench, EnvGPT earns top LLM-assigned scores for relevance (4.87 ± 0.11), factuality (4.70 ± 0.15), completeness (4.38 ± 0.19), and style (4.85 ± 0.10), outperforming baselines in every category. This study reveals how targeted supervised fine-tuning on curated domain data can propel compact LLMs to state-of-the-art levels, bridging gaps in environmental applications. By openly releasing EnvGPT, ChatEnv, and EnvBench, our work establishes a reproducible foundation for accelerating LLM adoption in environmental research, policy, and practice, with potential extensions to multimodal and real-time tools.}
}
@article{NAAGARAJAN2025101041,
title = {Enhancing greenhouse management with interpretable AI: A natural language interface for advanced and optimization-based control},
journal = {Smart Agricultural Technology},
volume = {11},
pages = {101041},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.101041},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525002746},
author = {Ramesh Arvind Naagarajan and Stefan Streif},
keywords = {Artificial Intelligence, Instructional prompting, Large language models, Model predictive control, Natural language generation, Retrieval augmented generation},
abstract = {As climate change and resource scarcity threaten global food security, greenhouse systems are becoming critical for sustainable agriculture. Advanced control, such as Model Predictive Control (MPC), effectively regulates temperature, humidity, and CO2 to enhance crop growth and resource efficiency. However, the widespread adoption of such advanced control systems is limited by their lack of interpretability, as growers struggle to understand complex control decisions, particularly during rapid environmental changes. In this work, a Natural Language Generation (NLG) interface has been developed to bridge this gap and transform MPC control decisions into clear, actionable explanations for greenhouse growers. This interface integrates Large Language Models (LLMs) with greenhouse control systems and mathematical constraints, providing a step toward making AI-driven agriculture more accessible. This integration addresses the need for interpretable AI systems in modern agricultural applications. The system allows growers to interact with the control system, query decisions, and receive contextually relevant explanations through Retrieval Augmented Generation (RAG) mechanisms and instruction prompting techniques. The Adaptive RAG (ARAG) framework was evaluated using semantic similarity, information retrieval, and contextual relevance metrics, demonstrating a 12.1% improvement in BERTScore, over baseline methods. These results highlight the system's ability to deliver accurate, well-structured explanations without compromising control performance. By improving the interpretability and accessibility of AI-powered greenhouse automation, this research advances the development of sustainable greenhouse practices that can adapt to the challenges of climate change and resource scarcity. The proposed system represents a significant step toward transforming traditional greenhouse control into more interpretable solutions for modern agriculture.}
}
@article{LI2025102983,
title = {Do ESG-conscious fund managers drive green innovation? An LLM-based textual analysis of fund manager narratives},
journal = {Research in International Business and Finance},
volume = {77},
pages = {102983},
year = {2025},
issn = {0275-5319},
doi = {https://doi.org/10.1016/j.ribaf.2025.102983},
url = {https://www.sciencedirect.com/science/article/pii/S0275531925002399},
author = {Yi Li and Tong Liu and Zhaohua Wang},
keywords = {Large Language Models, ESG Preferences, Fund Managers, Green Innovation},
abstract = {As ESG considerations gain increasing prominence, investors’ preferences for ESG factors are evolving, potentially influencing corporate governance practices. This study examines how fund managers’ ESG preferences affect the green innovation efforts of the firms they hold. Using large language models (LLMs) to analyze fund managers’ discussions in the quarterly reports of China’s mutual funds, we find that firms held by fund managers with stronger ESG preferences tend to demonstrate better green innovation performance. The positive impact of ESG-conscious fund managers on green innovation is primarily driven by increased R&D expenditures, the hiring of additional R&D personnel, and the alleviation of financing constraints. Additionally, the strength of this effect varies with factors such as analyst coverage, environmental performance, corporate governance structures of the firms, and the consistency of fund managers’ ESG preferences. This research not only highlights the utility of LLMs in corporate finance studies but also offers valuable insights into the role of fund managers’ personal preferences in shaping corporate governance and innovation strategies.}
}
@article{VENKATASUBRAMANIAN2025108908,
title = {Jaynes machine: The universal microstructure of deep neural networks},
journal = {Computers & Chemical Engineering},
volume = {192},
pages = {108908},
year = {2025},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2024.108908},
url = {https://www.sciencedirect.com/science/article/pii/S0098135424003260},
author = {Venkat Venkatasubramanian and N. Sanjeevrajan and Manasi Khandekar and Abhishek Sivaram and Collin Szczepanski},
keywords = {LLMs, Boltzmann machine, Hopfield networks, Game theory, Arbitrage equilibrium, Deep learning},
abstract = {Despite the recent stunning progress in large-scale deep neural network applications, our understanding of their microstructure, ‘energy’ functions, and optimal design remains incomplete. Here, we present a new game-theoretic framework, called statistical teleodynamics, that reveals important insights into these key properties. The optimally robust design of such networks inherently involves computational benefit–cost trade-offs that physics-inspired models do not adequately capture. These trade-offs occur as neurons and connections compete to increase their effective utilities under resource constraints during training. In a fully trained network, this results in a state of arbitrage equilibrium, where all neurons in a given layer have the same effective utility, and all connections to a given layer have the same effective utility. The equilibrium is characterized by the emergence of two lognormal distributions of connection weights and neuronal output as the universal microstructure of large deep neural networks. We call such a network the Jaynes Machine. Our theoretical predictions are shown to be supported by empirical data from seven large-scale deep neural networks. We also show that the Hopfield network and the Boltzmann Machine are the same special case of the Jaynes Machine.}
}
@article{FARHAT2024,
title = {Evaluating Large Language Models for the National Premedical Exam in India: Comparative Analysis of GPT-3.5, GPT-4, and Bard},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/51523},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000254},
author = {Faiza Farhat and Beenish Moalla Chaudhry and Mohammad Nadeem and Shahab Saquib Sohail and Dag Øivind Madsen},
keywords = {accuracy, AI model, artificial intelligence, Bard, ChatGPT, educational task, GPT-4, Generative Pre-trained Transformers, large language models, medical education, medical exam, natural language processing, performance, premedical exams, suitability},
abstract = {Background
Large language models (LLMs) have revolutionized natural language processing with their ability to generate human-like text through extensive training on large data sets. These models, including Generative Pre-trained Transformers (GPT)-3.5 (OpenAI), GPT-4 (OpenAI), and Bard (Google LLC), find applications beyond natural language processing, attracting interest from academia and industry. Students are actively leveraging LLMs to enhance learning experiences and prepare for high-stakes exams, such as the National Eligibility cum Entrance Test (NEET) in India.
Objective
This comparative analysis aims to evaluate the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions.
Methods
In this paper, we evaluated the performance of the 3 mainstream LLMs, namely GPT-3.5, GPT-4, and Google Bard, in answering questions related to the NEET-2023 exam. The questions of the NEET were provided to these artificial intelligence models, and the responses were recorded and compared against the correct answers from the official answer key. Consensus was used to evaluate the performance of all 3 models.
Results
It was evident that GPT-4 passed the entrance test with flying colors (300/700, 42.9%), showcasing exceptional performance. On the other hand, GPT-3.5 managed to meet the qualifying criteria, but with a substantially lower score (145/700, 20.7%). However, Bard (115/700, 16.4%) failed to meet the qualifying criteria and did not pass the test. GPT-4 demonstrated consistent superiority over Bard and GPT-3.5 in all 3 subjects. Specifically, GPT-4 achieved accuracy rates of 73% (29/40) in physics, 44% (16/36) in chemistry, and 51% (50/99) in biology. Conversely, GPT-3.5 attained an accuracy rate of 45% (18/40) in physics, 33% (13/26) in chemistry, and 34% (34/99) in biology. The accuracy consensus metric showed that the matching responses between GPT-4 and Bard, as well as GPT-4 and GPT-3.5, had higher incidences of being correct, at 0.56 and 0.57, respectively, compared to the matching responses between Bard and GPT-3.5, which stood at 0.42. When all 3 models were considered together, their matching responses reached the highest accuracy consensus of 0.59.
Conclusions
The study’s findings provide valuable insights into the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. GPT-4 emerged as the most accurate model, highlighting its potential for educational applications. Cross-checking responses across models may result in confusion as the compared models (as duos or a trio) tend to agree on only a little over half of the correct responses. Using GPT-4 as one of the compared models will result in higher accuracy consensus. The results underscore the suitability of LLMs for high-stakes exams and their positive impact on education. Additionally, the study establishes a benchmark for evaluating and enhancing LLMs’ performance in educational tasks, promoting responsible and informed use of these models in diverse learning environments.}
}
@article{LIU20241049,
title = {Research status and application of artificial intelligence large models in the oil and gas industry},
journal = {Petroleum Exploration and Development},
volume = {51},
number = {4},
pages = {1049-1065},
year = {2024},
issn = {1876-3804},
doi = {https://doi.org/10.1016/S1876-3804(24)60524-0},
url = {https://www.sciencedirect.com/science/article/pii/S1876380424605240},
author = {He LIU and Yili REN and Xin LI and Yue DENG and Yongtao WANG and Qianwen CAO and Jinyang DU and Zhiwei LIN and Wenjie WANG},
keywords = {foundation model, large language mode, visual large model, multimodal large model, large model of oil and gas industry, pre-training, fine-tuning},
abstract = {This article elucidates the concept of large model technology, summarizes the research status of large model technology both domestically and internationally, provides an overview of the application status of large models in vertical industries, outlines the challenges and issues confronted in applying large models in the oil and gas sector, and offers prospects for the application of large models in the oil and gas industry. The existing large models can be briefly divided into three categories: large language models, visual large models, and multimodal large models. The application of large models in the oil and gas industry is still in its infancy. Based on open-source large language models, some oil and gas enterprises have released large language model products using methods like fine-tuning and retrieval augmented generation. Scholars have attempted to develop scenario-specific models for oil and gas operations by using visual/multimodal foundation models. A few researchers have constructed pre-trained foundation models for seismic data processing and interpretation, as well as core analysis. The application of large models in the oil and gas industry faces challenges such as current data quantity and quality being difficult to support the training of large models, high research and development costs, and poor algorithm autonomy and control. The application of large models should be guided by the needs of oil and gas business, taking the application of large models as an opportunity to improve data lifecycle management, enhance data governance capabilities, promote the construction of computing power, strengthen the construction of “artificial intelligence + energy” composite teams, and boost the autonomy and control of large model technology.}
}
@article{ZHAO2025205,
title = {Cultural norms and corporate green transition disclosure: Unveiling the role of green innovation, social responsibility, and managerial myopia},
journal = {Economic Analysis and Policy},
volume = {87},
pages = {205-220},
year = {2025},
issn = {0313-5926},
doi = {https://doi.org/10.1016/j.eap.2025.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0313592625002334},
author = {Feng Zhao and Yanshun Huang and Yanting Zheng},
keywords = {Confucian culture, Corporate green transition disclosure, Machine learning, Informal institutions},
abstract = {Driven by China’s “dual carbon” goals, improving corporate green transition disclosure (GTD) systems has become a key path to achieving sustainable economic development. As China has yet to establish formal GTD institutions, this paper explores why companies voluntarily disclose their green transition information from the perspective of Confucian culture, an informal institution factor. Based on the “Management Discussion and Analysis” sections in corporate annual reports from 2007 to 2022, we use semantic recognition from machine learning models and text analysis to measure managers’ focus on green transition through two dimensions—innovation-driven initiatives and political compliance norms—to construct a GTD index. The findings show that a one-standard-deviation increase in Confucian cultural influence leads to a 3.61-standard-deviation increase in GTD. Confucian culture promotes GTD by curbing managers’ self-interest motives, encouraging green innovation, and fostering social responsibility. Furthermore, strengthened external environmental regulations and reduced environmental uncertainty amplify the positive effects of Confucian culture. Notably, the CEOs’ academic backgrounds reinforce these effects, whereas the presence of female executives attenuates them. This study offers methodological insights for quantifying firm-level GTD and provides a novel institutional perspective for evaluating green transition progress across countries and regions.}
}
@article{VARELAS2025104367,
title = {Artificial intelligence reveals unbalanced sustainability domains in funded research},
journal = {Results in Engineering},
volume = {25},
pages = {104367},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.104367},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025004487},
author = {Panagiotis Varelas and Francesca Larosa and Sergio Hoyas and J. Alberto Conejero and Francesco Contino and Francesco Fuso Nerini and Javier García-Martínez and Òscar Garibo-i-Orts and Alessandro Parente and Ricardo Vinuesa},
keywords = {AI, Sustainability, ChatGPT, SDGs, Funding Research, Scientific Funding, ERC, NSF},
abstract = {To meet the 2030 Agenda for Sustainable Development, all Sustainable Development Goals (SDGs) must receive adequate and balanced funding. This study applies artificial intelligence to analyze research proposals accepted between 2015 and 2023 in the European Union and the United States, focusing on datasets from the European Research Council and the National Science Foundation, respectively. Despite the growing application of Artificial Intelligence (AI) in various domains, there remains a lack of comprehensive analysis that applies AI to examine funding allocation across SDGs and gender disparities in scientific research. This study addresses this unmet need by using AI to uncover imbalances in funding distribution, offering insights into current funding instruments. We reveal critical coverage disparities across SDGs, with both funding instruments prioritizing SDG 9 (Industry, Innovation, and Infrastructure), highlighting a potential overemphasis on this goal. Additionally, we document pronounced gender imbalances among principal investigators across nearly all SDGs, except for SDG 5 (Gender Equality), in which female researchers are comparatively better represented. Our results indicate an urgent need for more inclusive and balanced approaches to achieve sustainable development, starting with allocation of research funding. By providing a nuanced understanding of funding dynamics and advocating strategic reallocations, this study offers actionable policy design and planning insights to foster a more equitable and comprehensive support system for sustainability-focused research endeavours.}
}
@article{YU2025105307,
title = {Exploring the prospects of multimodal large language models for Automated Emotion Recognition in education: Insights from Gemini},
journal = {Computers & Education},
volume = {232},
pages = {105307},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105307},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000752},
author = {Shuzhen Yu and Alexey Androsov and Hanbing Yan},
keywords = {Data science applications in education, Teaching/learning strategies, Multimodal large language models, Automated Emotion Recognition},
abstract = {Emotions play a pivotal role in daily judgments and decision-making, particularly in educational settings, where understanding and responding to learners’ emotions is essential for personalized learning. While there has been growing interest in emotion recognition, traditional methods, such as manual observations and self-reports, are often subjective and time-consuming. The rise of AI has led to the development of Automated Emotion Recognition (AER), offering transformative opportunities for educational reform by enabling personalized learning through emotional insights. However, AER continues to face challenges, including reliance on large-scale labeled databases, limited flexibility, and inadequate adaptation to diverse educational contexts. Recent advancements in AI, particularly Multimodal Large Language Models (MLLMs), show promise in addressing these challenges, though their application in AER remains underexplored. This study aimed to fill this gap by systematically evaluating the performance of Gemini, a pioneering MLLM, in image-based AER tasks across five databases: CK+, FER-2013, RAF-DB, OL-SFED and DAiSEE. The analysis examined recognition accuracy, error patterns, emotion inference mechanisms, and the impact of image preprocessing techniques — such as face cropping, bilinear interpolation, and super-resolution — on the model’s performance. The results revealed that Gemini achieved high emotion recognition accuracy, especially in distinguishing emotional polarities across all databases. Image preprocessing significantly improved the recognition of basic emotions, though its effect on academic emotion recognition was minor. The confusion in academic emotion recognition stemmed from Gemini’s limited understanding of academic emotion features and its insufficient ability to capture contextual cues. Building on the results, this study outlines specific future research directions from both technological and educational perspectives. These findings offer valuable insights for advancing MLLMs in educational applications.}
}
@article{ZHAO2025562,
title = {Intelligent Agent-based Analysis of Collaborative Problem Solving Skills in Sessions},
journal = {Procedia Computer Science},
volume = {266},
pages = {562-569},
year = {2025},
note = {The 12th International Conference on Information Technology and Quantitative Management (ITQM 2025)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.08.071},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925023774},
author = {Yilin Zhao and Juanqiong Gou and Fangcong Zhang and Mengxin Zhang and Xiaodan Yu},
keywords = {Collaborative Problem Solving Skills, Session, Human-to-Human Collaboraion, Large Language Model, Intelligent Agent},
abstract = {Collaborative Problem Solving Skills (CPS Skills) as the core literacy of talents in the 21st century, the analysis and assessment of it is an important issue in the field of education. With the advancement of digitalization and intelligence in education, the application of artificial intelligence technology in education tends to be the norm, which also brings more opportunities and challenges to the analysis of CPS skills. At present, CPS skills assessment is mainly conducted based on computers with high training costs. The superior creation ability, reasoning ability and interpretability of AI agents can precisely solve the limitations of the current computer-based analysis and assessment of students’ abilities. In this paper, we propose an analysis method of CPS skills based on students’ conversation data in complex problem situations, and design an AI agent framework based on the method to automate the analysis and assessment of CPS skills, to provide scientific and effective evaluation tools and improvement suggestions for the educational practice in the intelligent era.}
}
@article{JIN2025130450,
title = {Will the technological singularity come soon? Modeling the dynamics of artificial intelligence development via multi-logistic growth process},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {664},
pages = {130450},
year = {2025},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2025.130450},
url = {https://www.sciencedirect.com/science/article/pii/S0378437125001025},
author = {Guangyin Jin and Xiaohan Ni and Kun Wei and Jie Zhao and Haoming Zhang and Leiming Jia},
keywords = {Technological singularity, Artificial intelligence, Development dynamics, Multi-logistic growth},
abstract = {We are currently in an era of escalating technological complexity and profound societal transformations, where artificial intelligence (AI) technologies exemplified by large language models (LLMs) have reignited discussions on the ‘Technological Singularity’. ‘Technological Singularity’ is a philosophical concept referring to an irreversible and profound transformation that occurs when AI capabilities surpass those of humans comprehensively. However, quantitative modeling and analysis of the historical evolution and future trends of AI technologies remain scarce, failing to substantiate the singularity hypothesis adequately. This paper hypothesizes that the development of AI technologies could be characterized by the superposition of multiple logistic growth processes. To explore this hypothesis, we propose a multi-logistic growth process model and validate it using two real-world datasets: AI Historical Statistics and Arxiv AI Papers. Our analysis of the AI Historical Statistics dataset assesses the effectiveness of the multi-logistic model and evaluates the current and future trends in AI technology development. Additionally, cross-validation experiments on the Arxiv AI Paper, GPU Transistor and Internet User dataset enhance the robustness of our conclusions derived from the AI Historical Statistics dataset. The experimental results reveal that around 2024 marks the fastest point of the current AI wave, and the deep learning-based AI technologies are projected to decline around 2035–2040 if no fundamental technological innovation emerges. Consequently, the technological singularity appears unlikely to arrive in the foreseeable future.}
}
@article{WILLEMS20251046,
title = {Sustainability target system for product development to support the identification and addressability of problem shifts},
journal = {Procedia CIRP},
volume = {135},
pages = {1046-1051},
year = {2025},
note = {32nd CIRP Conference on Life Cycle Engineering (LCE2025)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.01.085},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125003932},
author = {Wilke Willems and Fabian R. Rusch and Niels Demke and Frank Mantwill},
keywords = {sustainability target systems, product development, product life cycle, requirements, early phase considerations, interoperability, situational awarness, communication, life cycle engineering, holistic sustainability model, requirements derivation, sustainability problem shifts},
abstract = {Due to shifts in society sustainable products are increasingly gaining market attention while laws regulate realization. Known sustainability models primarily focus on social and ecological factors relating to people and their environment. The consideration of sustainability in product development requires an addressable translation as well as the inclusion of economic aspects. In this paper, a sustainability target system for product development is proposed to enhance interoperability between sustainability models and product development and to systematically support analyzing problem shifts. Based on a literature review, the capability of influencing the target variables is evaluated considering the phases of the product life cycle and generalizable problem shifts. Using a requirements methodology for goals, restrictions, solutions, and an assigned syntax, the problem shifts in product development can be identified, captured, and addressed. For the validation, an implementation of requirements for a sustainability certification of a product is examined. As a result, the sustainability target system for product development supports the product developers in gaining situational awareness due to a sharper focus on relevant target variables and the lifecycle phases in which they can be influenced. Finally, this approach enables potential for the implementation of computer-aided assistance systems.}
}
@article{STORNAIUOLO202483,
title = {Digital writing with AI platforms: the role of fun with/in generative AI},
journal = {English Teaching: Practice & Critique},
volume = {23},
number = {1},
pages = {83-103},
year = {2024},
issn = {1175-8708},
doi = {https://doi.org/10.1108/ETPC-08-2023-0103},
url = {https://www.sciencedirect.com/science/article/pii/S1175870824000189},
author = {Amy Stornaiuolo and Jennifer Higgs and Opal Jawale and Rhianne Mae Martin},
keywords = {Creativity, Artificial intelligence, Literacy, AI, Platforms, Multiliteracies, Character.ai, Digital writing, Postdigital},
abstract = {Purpose
With the rapid advancement of generative artificial intelligence (AI), it is important to consider how young people are making sense of these tools in their everyday lives. Drawing on critical postdigital approaches to learning and literacy, this study aims to center the experiences and perspectives of young people who encounter and experiment with generative AI in their daily writing practices.
Design/methodology/approach
This critical case study of one digital platform – Character.ai – brings together an adolescent and adult authorship team to inquire about the intertwining of young people’s playful and critical perspectives when writing on/with digital platforms. Drawing on critical walkthrough methodology (Light et al., 2018), the authors engage digital methods to study how the creative and “fun” uses of AI in youths’ writing lives are situated in broader platform ecologies.
Findings
The findings suggest experimentation and pleasure are key aspects of young people’s engagement with generative AI. The authors demonstrate how one platform works to capitalize on these dimensions, even as youth users engage critically and artfully with the platform and develop their digital writing practices.
Practical implications
This study highlights how playful experimentation with generative AI can engage young people both in pleasurable digital writing and in exploration and contemplation of platforms dynamics and structures that shape their and others’ literate activities. Educators can consider young people’s creative uses of these evolving technologies as potential opportunities to develop a critical awareness of how commercial platforms seek to benefit from their users.
Originality/value
This study contributes to the development of a critical and humanist research agenda around generative AI by centering the experiences, perspectives and practices of young people who are underrepresented in the burgeoning research devoted to AI and literacies.}
}
@article{MU2024128514,
title = {Multi-agent, human–agent and beyond: A survey on cooperation in social dilemmas},
journal = {Neurocomputing},
volume = {610},
pages = {128514},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128514},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224012852},
author = {Chunjiang Mu and Hao Guo and Yang Chen and Chen Shen and Die Hu and Shuyue Hu and Zhen Wang},
keywords = {Social dilemma, Sequential social dilemma, Human–agent cooperation, Multi-agent reinforcement learning},
abstract = {The study of cooperation within social dilemmas has long been a fundamental topic across various disciplines, including computer science and social science. Recent advancements in Artificial Intelligence (AI) have significantly reshaped this field, offering fresh insights into understanding and enhancing cooperation. This survey examines three key areas at the intersection of AI and cooperation in social dilemmas. First, focusing on multi-agent cooperation, we review the intrinsic and external motivations that support cooperation among rational agents, and the methods employed to develop effective strategies against diverse opponents. Second, looking into human–agent cooperation, we discuss the current AI algorithms for cooperating with humans and the human biases towards AI agents. Third, we review the emergent field of leveraging AI agents to enhance cooperation among humans. We conclude by discussing future research avenues, such as using large language models, establishing unified theoretical frameworks, revisiting existing theories of human cooperation, and exploring multiple real-world applications.}
}
@article{AALTONEN2024102649,
title = {Stakeholder engagement: Theoretical and methodological directions for project scholarship},
journal = {International Journal of Project Management},
volume = {42},
number = {7},
pages = {102649},
year = {2024},
issn = {0263-7863},
doi = {https://doi.org/10.1016/j.ijproman.2024.102649},
url = {https://www.sciencedirect.com/science/article/pii/S0263786324000917},
author = {Kirsi Aaltonen and Roya Derakhshan and Francesco {Di Maddaloni} and Rodney Turner},
abstract = {In our introduction to this Special Issue on Project Stakeholder Engagement, we emphasize the imperative for a deeper understanding of stakeholder phenomena in the context of temporary organizations. Our argument addresses the growing need for organizational strategies that focus on more inclusive approaches, the moral foundations of stakeholder thinking, and the necessity of considering marginalized groups. Recent debates in management and organizational scholarship have conveyed a key message to organizations: the need for them to contribute to a more cohesive and sustainable world. However, this paradigm shift from stakeholder ‘management’ to ‘engagement’ also presents new challenges for (project) organizations as they seek to address and balance the needs and demands of multiple stakeholders. Such approaches require more collaborative and inclusive structures to tackle pressing social issues and to recognize a broader array of stakeholders in value-creation processes. Against this backdrop, the focus of this Special Issue is on advancing theory and evidence related to the nature, aims, processes, and consequences of stakeholder engagement in temporary organizations. We summarize the contributions of each of the six articles that make up this Special Issue, noting in particular their methodological and theoretical diversity. In conclusion, we propose a future research agenda on project stakeholder engagement, inspired by the ideas and insights developed in this Special Issue.}
}